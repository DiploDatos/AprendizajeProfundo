{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DiploDatos/AprendizajeProfundo/blob/master/8_automated_hyperparameter_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qy2yUgKC8vsg"
   },
   "source": [
    "# Búsqueda de Hiperparámetros\n",
    "\n",
    "Las redes neuronales tienen decenas de hiperparámetros que afectan su arquitectura y proceso de entrenamiento. Más aún, el desempeño final del modelo está condicionado a encontar un conjunto de valores para dichos hiperparámetros exitosos, para una inicialización aleatoria de los pesos dada. Por ello, la exploración de hiperparámetros se vuelve una de las partes más tediosas y críticas del entrenamiento de redes neuronales. Para obtener resultados que sean correctos, significativos y reproducibles es necesario planificar y sistemizar este proceso de búsqueda.\n",
    "\n",
    "  >  hyper-parameter optimization should be regarded as a formal outer loop in the learning process\n",
    "\n",
    "Formalmente, este proceso se puede describir como la minimización de la función de pérdida (o maximizar la performance) como si fuera una función de *caja negra* que toma como parámetros los valores de los hiperparámetros:\n",
    "\n",
    "$$ f(\\theta) = loss_\\theta(y, \\hat{y}) $$\n",
    "$$ \\theta^* = argmin_\\theta f(\\theta) $$\n",
    "\n",
    "donde $\\theta$ es el conjunto de hiperparámetros del modelo, $loss$ es la pérdida generada entre las etiquetas verdaderas $y$ y las etiquetas generadas por el modelo $\\hat{y}$, y $f$ es la función objetivo de la minimización.\n",
    "\n",
    "\n",
    "Las estrategias principales para la exploración del espacio de hiperparámetros son:\n",
    "* Búsqueda manual, donde un humano define los valores de cada hiperparámetro.\n",
    "* Búsqueda por grilla o *grid search*, donde se define un conjunto de valores posibles que puede tomar cada hiperparámetro, y se realiza un experimento por cada combinación posible.\n",
    "* Búsqueda aleatoria o *random search*, donde se define un rango de valores posibles para cada hiperparámetro, y se elige al azar un valor del rango para cada experimento.\n",
    "* Búsqueda automátizada, *automated search* o *model-based search*, que es igual a la búsqueda aleatoria pero la selección del valor de cada hiperparámetro está condicionado por los resultados de experimentos anteriores. Para más información ver el paper [*Algorithms for Hyper-Parameter Optimization*](https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf)\n",
    "\n",
    "En la siguiente imagen, tomada del paper [*Random Search for Hyper-Parameter Optimization*](https://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf), se muestra el impacto de las primeras dos estrategias para un hiperparámetro con alta influencia en el desempeño del modelo final, y otro que sin influencia. No solo require muchas evaluaciones para lograr cobertura, sino que las combinaciones en dónde sólo se varían hiperparámetros no relevantes no recolectan información nueva. El éxito de la búsqueda por grilla depende de que el nivel de granularidad de la grilla cubra adecuadamente los valores relevantes, que son desconocidos a priori.\n",
    "\n",
    "![Comparación de las exploraciones entre grid search y random search](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1531340388/grid_vs_random_jltknd.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZnHi2iN7BiA"
   },
   "source": [
    "Para solucionar todos estos problemas, es que se utiliza la **exploración bayesiana**. Este método modela la loss como un Gaussian process, y tiene en cuenta los resultados de los experimentos anteriores para ir construyendo una distribución de probabilidad de la pérdida dados los hiperparámetros:\n",
    "\n",
    "$$ P(loss | \\theta)$$\n",
    "\n",
    "Para elegir una nueva combinación de hiperparámetros a probar dados los experimentos previos, el algoritmo utiliza una *surrogate function* para aproximar el comportamiento de la pérdida y una *selection function* basada en la mejora esperada. A grandes rasgos, el algoritmo sigue los siguientes pasos:\n",
    "\n",
    "  1. Encontrar el mejor conjunto de hiperparámetros que maximize la mejora esperada (EI), estimada a través de la *surrogate function*.\n",
    "  2. Calcular la performance del modelo con la combinación de hiperparámetros elegida. Esto corresponde a evaluar la función objetivo.\n",
    "  3. Actualizar la forma de la *surrogate function* utilizando el teorema de Bayes para que se ajuste mejor a la verdadera distribución $ P(loss | \\theta)$\n",
    "\n",
    "Afortunadamente, muchos algoritmos de búsqueda están implementados y funcionan como cajas negras. Veremos un ejemplo utilizando la librería Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hUunZMB_gk2",
    "outputId": "c0ec776a-249a-4b43-9ce3-d5a974c46c5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "# If running in colab, you need to update gensim\n",
    "# !pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VJmgwjm48vso"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import functools\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tempfile\n",
    "import seaborn\n",
    "\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.parsing import preprocessing\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from tqdm.notebook import tqdm, trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "t0XhsOvd_nbC",
    "outputId": "8de096c8-c530-4861-b94b-9e3835af99b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure version 4.X\n",
    "import gensim\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUzR6Nfv8vsp"
   },
   "source": [
    "## Parte 1: Preprocesamiento del texto\n",
    "\n",
    "Primero leeremos el dataset como se explica en la notebook 5_cnns.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sLySwHxR-l2W"
   },
   "outputs": [],
   "source": [
    "# If necessary, download data\n",
    "# %%bash\n",
    "# mkdir data\n",
    "# curl -L https://cs.famaf.unc.edu.ar/\\~ccardellino/resources/diplodatos/glove.6B.50d.txt.gz -o ./data/glove.6B.50d.txt.gz\n",
    "# curl -L https://cs.famaf.unc.edu.ar/\\~ccardellino/resources/diplodatos/imdb_reviews.csv.gz -o ./data/imdb_reviews.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bVdiWbML8vsq"
   },
   "outputs": [],
   "source": [
    "class IMDBReviewsDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if torch.is_tensor(item):\n",
    "            item = item.to_list()\n",
    "        \n",
    "        item = {\n",
    "            \"data\": self.dataset.loc[item, \"review\"],\n",
    "            \"target\": self.dataset.loc[item, \"sentiment\"]\n",
    "        }\n",
    "        \n",
    "        if self.transform:\n",
    "            item = self.transform(item)\n",
    "        \n",
    "        return item\n",
    "\n",
    "class RawDataProcessor:\n",
    "    def __init__(self, \n",
    "                 dataset, \n",
    "                 ignore_header=True, \n",
    "                 filters=None, \n",
    "                 vocab_size=50000):\n",
    "        if filters:\n",
    "            self.filters = filters\n",
    "        else:\n",
    "            self.filters = [\n",
    "                lambda s: s.lower(),\n",
    "                preprocessing.strip_tags,\n",
    "                preprocessing.strip_punctuation,\n",
    "                preprocessing.strip_multiple_whitespaces,\n",
    "                preprocessing.strip_numeric,\n",
    "                preprocessing.remove_stopwords,\n",
    "                preprocessing.strip_short,\n",
    "            ]\n",
    "        \n",
    "        # Create dictionary based on all the reviews (with corresponding preprocessing)\n",
    "        self.dictionary = corpora.Dictionary(\n",
    "            dataset[\"review\"].map(self._preprocess_string).tolist()\n",
    "        )\n",
    "        # Filter the dictionary and compactify it (make the indices continous)\n",
    "        self.dictionary.filter_extremes(no_below=2, no_above=1, keep_n=vocab_size)\n",
    "        self.dictionary.compactify()\n",
    "        # Add a couple of special tokens\n",
    "        self.dictionary.patch_with_special_tokens({\n",
    "            \"[PAD]\": 0,\n",
    "            \"[UNK]\": 1\n",
    "        })\n",
    "        self.idx_to_target = sorted(dataset[\"sentiment\"].unique())\n",
    "        self.target_to_idx = {t: i for i, t in enumerate(self.idx_to_target)}\n",
    "\n",
    "    def _preprocess_string(self, string):\n",
    "        return preprocessing.preprocess_string(string, filters=self.filters)\n",
    "\n",
    "    def _sentence_to_indices(self, sentence):\n",
    "        return self.dictionary.doc2idx(sentence, unknown_word_index=1)\n",
    "    \n",
    "    def encode_data(self, data):\n",
    "        return self._sentence_to_indices(self._preprocess_string(data))\n",
    "    \n",
    "    def encode_target(self, target):\n",
    "        return self.target_to_idx[target]\n",
    "    \n",
    "    def __call__(self, item):\n",
    "        if isinstance(item[\"data\"], str):\n",
    "            data = self.encode_data(item[\"data\"])\n",
    "        else:\n",
    "            data = [self.encode_data(d) for d in item[\"data\"]]\n",
    "        \n",
    "        if isinstance(item[\"target\"], str):\n",
    "            target = self.encode_target(item[\"target\"])\n",
    "        else:\n",
    "            target = [self.encode_target(t) for t in item[\"target\"]]\n",
    "        \n",
    "        return {\n",
    "            \"data\": data,\n",
    "            \"target\": target,\n",
    "            \"sentence\": item[\"data\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N38F6o3VAYSD"
   },
   "source": [
    "### Separando el conjunto de validación o *dev*\n",
    "\n",
    "En deep learning, es **MUY** importante utilizar un conjunto de validación durante la búsqueda de hiperparámetros, que puede ser tomado de la partición de entrenamiento. Esto es independiente de la estrategia de búsqueda que se utilice.\n",
    "\n",
    "De esta manera, se previene el overfitting indirecto y se cuenta con una partición de datos nunca antes vista para poder evaluar la generalización real del modelo a datos no vistos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fdxy4poX_8_3"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/imdb_reviews.csv.gz\")\n",
    "preprocess = RawDataProcessor(dataset)\n",
    "train_indices, test_indices = train_test_split(dataset.index, test_size=0.2, random_state=42)\n",
    "train_indices, dev_indices = train_test_split(train_indices, test_size=0.2, random_state=42)\n",
    "train_dataset = IMDBReviewsDataset(dataset.loc[train_indices].reset_index(drop=True), transform=preprocess)\n",
    "dev_dataset = IMDBReviewsDataset(dataset.loc[dev_indices].reset_index(drop=True), transform=preprocess)\n",
    "# We won't use test_dataset until the end!\n",
    "test_dataset = IMDBReviewsDataset(dataset.loc[test_indices].reset_index(drop=True), transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gemdFTfO8ELO"
   },
   "outputs": [],
   "source": [
    "class PadSequences:\n",
    "    def __init__(self, pad_value=0, max_length=100):\n",
    "        self.pad_value = pad_value\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, items):\n",
    "        data, target = list(zip(*[(item[\"data\"], item[\"target\"]) for item in items]))\n",
    "        seq_lengths = [len(d) for d in data]\n",
    "\n",
    "        max_length = self.max_length\n",
    "        seq_lengths = [min(self.max_length, l) for l in seq_lengths]\n",
    "\n",
    "        data = [d[:l] + [self.pad_value] * (max_length - l)\n",
    "                for d, l in zip(data, seq_lengths)]\n",
    "            \n",
    "        return {\n",
    "            \"data\": torch.LongTensor(data),\n",
    "            \"target\": torch.FloatTensor(target)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPpIPlkr8vsx"
   },
   "source": [
    "## Parte 2: Esqueleto de la red neuronal\n",
    "\n",
    "Definimos el modelo a entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tq6C63l-8vsy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LVWbyNkq8vsz"
   },
   "outputs": [],
   "source": [
    "class ImdbLSTM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 pretrained_embeddings_path, dictionary, embedding_size,\n",
    "                 hidden_layer=32,\n",
    "                 num_layers=1, dropout=0., bias=True,\n",
    "                 bidirectional=False,\n",
    "                 freeze_embedings=True):\n",
    "        \n",
    "        super(ImdbLSTM, self).__init__()\n",
    "        output_size = 1\n",
    "        # Create the Embeddings layer and add pre-trained weights\n",
    "        embeddings_matrix = torch.randn(len(dictionary), embedding_size)\n",
    "        embeddings_matrix[0] = torch.zeros(embedding_size)\n",
    "        with gzip.open(pretrained_embeddings_path, \"rt\") as fh:\n",
    "            for line in fh:\n",
    "                word, vector = line.strip().split(None, 1)\n",
    "                if word in dictionary.token2id:\n",
    "                    embeddings_matrix[dictionary.token2id[word]] =\\\n",
    "                        torch.FloatTensor([float(n) for n in vector.split()])\n",
    "        self.embedding_config = {'freeze': freeze_embedings,\n",
    "                                  'padding_idx': 0}\n",
    "        self.embeddings = nn.Embedding.from_pretrained(\n",
    "            embeddings_matrix, **self.embedding_config)\n",
    "        \n",
    "        # Set our LSTM parameters\n",
    "        self.lstm_config = {'input_size': embedding_size,\n",
    "                            'hidden_size': hidden_layer,\n",
    "                            'num_layers': num_layers,\n",
    "                            'bias': bias,\n",
    "                            'batch_first': True,\n",
    "                            'dropout': dropout if num_layers > 1 else 0.0,\n",
    "                            'bidirectional': bidirectional}\n",
    "        \n",
    "        # Set our fully connected layer parameters\n",
    "        self.linear_config = {'in_features': hidden_layer,\n",
    "                              'out_features': output_size,\n",
    "                              'bias': bias}\n",
    "        \n",
    "        # Instanciate the layers\n",
    "        self.lstm = nn.LSTM(**self.lstm_config)\n",
    "        self.droupout_layer = nn.Dropout(dropout)\n",
    "        self.classification_layer = nn.Linear(**self.linear_config)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        emb = self.embeddings(inputs)\n",
    "        lstm_out, _ = self.lstm(emb)\n",
    "        # Take last state of lstm, which is a representation of\n",
    "        # the entire text\n",
    "        lstm_out = lstm_out[:, -1, :].squeeze()\n",
    "        lstm_out = self.droupout_layer(lstm_out)\n",
    "        predictions = self.activation(self.classification_layer(lstm_out))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ej4JfQx57nmw"
   },
   "source": [
    "Encapsularemos el algoritmo de entrenamiento dentro de una función parametrizable. La función debería devolver los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JO279TL-2BMr"
   },
   "outputs": [],
   "source": [
    "# Some default values\n",
    "EPOCHS = 2\n",
    "MAX_SEQUENCE_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LHnG8wj07mX-"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_imbd_model(train_dataset, dev_dataset,\n",
    "                     pretrained_embeddings_path, dictionary, embedding_size,\n",
    "                     batch_size=128, max_sequence_len=MAX_SEQUENCE_LEN,\n",
    "                     hidden_layer=32, dropout=0.,\n",
    "                     epochs=EPOCHS, lr=0.001, optimizer_class=optim.Adam,\n",
    "                     verbose=False):\n",
    "\n",
    "    if verbose:\n",
    "        print_fn = print\n",
    "    else:\n",
    "        print_fn = lambda *x: None\n",
    "    # We define again the data loaders since this code could run in\n",
    "    # parallel\n",
    "    pad_sequeces = PadSequences(max_length=max_sequence_len)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                              collate_fn=pad_sequeces, drop_last=False)\n",
    "    dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False,\n",
    "                            collate_fn=pad_sequeces, drop_last=False)\n",
    "\n",
    "    # We are not going to explore all hyperparameters, only this ones.\n",
    "    model = ImdbLSTM(pretrained_embeddings_path, dictionary, embedding_size,\n",
    "                     hidden_layer=hidden_layer, dropout=dropout)\n",
    "\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer = optimizer_class(model.parameters(), lr)\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'test_loss': [],\n",
    "        'test_avp': []\n",
    "    }\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = []\n",
    "        print_fn(\"Epoch\", epoch)\n",
    "        for idx, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch[\"data\"])\n",
    "            loss_value = loss_function(output.squeeze(), batch[\"target\"])\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            running_loss.append(loss_value.item())\n",
    "        train_loss = sum(running_loss) / len(running_loss)\n",
    "        print_fn(\"\\t Final train_loss\", train_loss)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        running_loss = []\n",
    "        targets = []\n",
    "        predictions = []\n",
    "        for batch in dev_loader:\n",
    "            output = model(batch[\"data\"])\n",
    "            running_loss.append(\n",
    "                loss_function(output.squeeze(), batch[\"target\"]).item()\n",
    "            )\n",
    "            targets.extend(batch[\"target\"].numpy())\n",
    "            # Round up model output to get the predictions.\n",
    "            # What would happen if you change the activation to tanh?\n",
    "            predictions.extend(output.squeeze().round().detach().numpy())\n",
    "        test_loss = sum(running_loss) / len(running_loss)\n",
    "        avp = metrics.average_precision_score(targets, predictions)\n",
    "        print_fn(\"\\t Final test_loss\", test_loss)\n",
    "        print_fn(\"\\t Final test_avp\", avp)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_avp'].append(avp)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WEzziR8j8vs0",
    "outputId": "d0f4e0b4-8646-4234-d4b3-19492be26298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\t Final train_loss 0.6763483471870423\n",
      "\t Final test_loss 0.6396069403678651\n",
      "\t Final test_avp 0.6313642773343966\n",
      "Epoch 1\n",
      "\t Final train_loss 0.6783126583099365\n",
      "\t Final test_loss 0.6633364823129442\n",
      "\t Final test_avp 0.5721578542649114\n"
     ]
    }
   ],
   "source": [
    "history = train_imbd_model(\n",
    "    train_dataset, dev_dataset,\n",
    "    pretrained_embeddings_path=\"./data/glove.6B.50d.txt.gz\",\n",
    "    dictionary=preprocess.dictionary, embedding_size=50, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5721578542649114"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['test_avp'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDw_sn_E8vs1"
   },
   "source": [
    "## Utilizando Optuna\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna pide que tengamos ciertas cosas en nuestro código:\n",
    "- Una funcion de objetivo a minimizar o maximizar\n",
    "- Una declaración de hiperparámetros a probar\n",
    "- Cómo operar dentro de un _trial_\n",
    "- Estudio\n",
    "\n",
    "Primero redefinamos el training loop para usar optuna. De esta forma accedemos a una funciones muy útiles de Optuna como el [pruning](https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/003_efficient_optimization_algorithms.html?highlight=pruning#pruning-algorithms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_train_imbd_model(\n",
    "                     trial: optuna.trial, # <--- esto es lo importante\n",
    "                     train_dataset, dev_dataset,\n",
    "                     pretrained_embeddings_path, dictionary, embedding_size,\n",
    "                     batch_size=128, max_sequence_len=MAX_SEQUENCE_LEN,\n",
    "                     hidden_layer=32, dropout=0.,\n",
    "                     epochs=EPOCHS, lr=0.001, optimizer_class=optim.Adam,\n",
    "                     verbose=False):\n",
    "    if verbose:\n",
    "        print_fn = print\n",
    "    else:\n",
    "        print_fn = lambda *x: None\n",
    "    # We define again the data loaders since this code could run in\n",
    "    # parallel\n",
    "    pad_sequeces = PadSequences(max_length=max_sequence_len)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                              collate_fn=pad_sequeces, drop_last=False)\n",
    "    dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False,\n",
    "                            collate_fn=pad_sequeces, drop_last=False)\n",
    "\n",
    "    # We are not going to explore all hyperparameters, only this ones.\n",
    "    model = ImdbLSTM(pretrained_embeddings_path, dictionary, embedding_size,\n",
    "                     hidden_layer=hidden_layer, dropout=dropout)\n",
    "\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer = optimizer_class(model.parameters(), lr)\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'test_loss': [],\n",
    "        'test_avp': []\n",
    "    }\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = []\n",
    "        print_fn(\"Epoch\", epoch)\n",
    "        for idx, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch[\"data\"])\n",
    "            loss_value = loss_function(output.squeeze(), batch[\"target\"])\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            running_loss.append(loss_value.item())\n",
    "        train_loss = sum(running_loss) / len(running_loss)\n",
    "        print_fn(\"\\t Final train_loss\", train_loss)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        running_loss = []\n",
    "        targets = []\n",
    "        predictions = []\n",
    "        for batch in dev_loader:\n",
    "            output = model(batch[\"data\"])\n",
    "            running_loss.append(\n",
    "                loss_function(output.squeeze(), batch[\"target\"]).item()\n",
    "            )\n",
    "            targets.extend(batch[\"target\"].numpy())\n",
    "            # Round up model output to get the predictions.\n",
    "            # What would happen if you change the activation to tanh?\n",
    "            predictions.extend(output.squeeze().round().detach().numpy())\n",
    "        test_loss = sum(running_loss) / len(running_loss)\n",
    "        avp = metrics.average_precision_score(targets, predictions)\n",
    "        print_fn(\"\\t Final test_loss\", test_loss)\n",
    "        print_fn(\"\\t Final test_avp\", avp)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_avp'].append(avp)\n",
    "        \n",
    "        # Report optimizing value to optuna\n",
    "        trial.report(history['test_loss'][-1], epoch)\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo el training es igual excepto por la inclusion del ```trial: optuna.trial```, que es un objeto de Optuna que se encarga de llevar seguimiento de una experimento específico con parámetros muestreados de una distribución.\n",
    "\n",
    "Al acceder a un trial, optuna nos permite terminar prematuramente experimentos no prometedores con el uso de un Pruner: si el resultado muestra mejorías y es peor a resultados anteriores, se termina el entrenamiento y se mueve al siguiente trial.\n",
    "\n",
    "Para definir los hiperparámetros para los cuales queremos muestrear valores, debemos usar los métodos ```suggest_*``` del mismo trial. Para este ejemplo usaremos los métodos ```suggest_float``` y ```suggest_categorical``` para muestrear valores para el learning rate, el dropout y el optimizador.\n",
    "\n",
    "Para más información de los valores que podemos muestrear, consultar la [documentación de Optuna](https://optuna.readthedocs.io/en/v1.1.0/reference/trial.html?highlight=trial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # Set optuna space search\n",
    "    optims = {'Adam': optim.Adam,\n",
    "              'RMSprop': optim.RMSprop}\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam',\n",
    "                                                             'RMSprop'])\n",
    "    optimizer_class = optims[optimizer_name]\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    \n",
    "    history = optuna_train_imbd_model(\n",
    "        trial,\n",
    "        train_dataset, dev_dataset,\n",
    "        pretrained_embeddings_path=\"./data/glove.6B.50d.txt.gz\",\n",
    "        dictionary=preprocess.dictionary, embedding_size=50,\n",
    "        lr=lr,\n",
    "        optimizer_class=optimizer_class,\n",
    "        dropout=dropout)\n",
    "    \n",
    "    # This is the value that will be minimized!            \n",
    "    return history['test_loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-23 12:34:24,717]\u001b[0m A new study created in memory with name: no-name-4476815c-d0cd-4152-806a-d13d161c8761\u001b[0m\n",
      "\u001b[32m[I 2022-09-23 12:36:55,526]\u001b[0m Trial 0 finished with value: 0.6930831869443258 and parameters: {'lr': 0.006084575186402038, 'optimizer': 'Adam', 'dropout': 0.27568295002047466}. Best is trial 0 with value: 0.6930831869443258.\u001b[0m\n",
      "\u001b[32m[I 2022-09-23 12:39:02,772]\u001b[0m Trial 1 finished with value: 0.6128588924332271 and parameters: {'lr': 0.0007412787605150763, 'optimizer': 'Adam', 'dropout': 0.391211136945459}. Best is trial 1 with value: 0.6128588924332271.\u001b[0m\n",
      "\u001b[32m[I 2022-09-23 12:40:48,294]\u001b[0m Trial 2 finished with value: 0.6266448488311162 and parameters: {'lr': 0.061106317059916655, 'optimizer': 'RMSprop', 'dropout': 0.2329279707931622}. Best is trial 1 with value: 0.6128588924332271.\u001b[0m\n",
      "\u001b[32m[I 2022-09-23 12:42:21,124]\u001b[0m Trial 3 finished with value: 0.692151961818574 and parameters: {'lr': 2.7776045098870157e-05, 'optimizer': 'Adam', 'dropout': 0.20023184547822054}. Best is trial 1 with value: 0.6128588924332271.\u001b[0m\n",
      "\u001b[32m[I 2022-09-23 12:44:00,096]\u001b[0m Trial 4 finished with value: 0.4476667179001702 and parameters: {'lr': 0.03382727347205365, 'optimizer': 'Adam', 'dropout': 0.04125212145580892}. Best is trial 4 with value: 0.4476667179001702.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=5, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value:  0.4476667179001702\n",
      "  Params: \n",
      "    lr: 0.03382727347205365\n",
      "    optimizer: Adam\n",
      "    dropout: 0.04125212145580892\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "optimizer (CategoricalDistribution): 0.13300029994067813<extra></extra>",
          "lr (LogUniformDistribution): 0.25645897317655214<extra></extra>",
          "dropout (UniformDistribution): 0.6105407268827697<extra></extra>"
         ],
         "marker": {
          "color": "rgb(66,146,198)"
         },
         "orientation": "h",
         "text": [
          "0.13300029994067813",
          "0.25645897317655214",
          "0.6105407268827697"
         ],
         "textposition": "outside",
         "texttemplate": "%{text:.2f}",
         "type": "bar",
         "x": [
          0.13300029994067813,
          0.25645897317655214,
          0.6105407268827697
         ],
         "y": [
          "optimizer",
          "lr",
          "dropout"
         ]
        }
       ],
       "layout": {
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Importance for Objective Value"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"6d569937-2c16-4158-adeb-c8800a53fa10\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6d569937-2c16-4158-adeb-c8800a53fa10\")) {                    Plotly.newPlot(                        \"6d569937-2c16-4158-adeb-c8800a53fa10\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"optimizer (CategoricalDistribution): 0.13300029994067813<extra></extra>\",\"lr (LogUniformDistribution): 0.25645897317655214<extra></extra>\",\"dropout (UniformDistribution): 0.6105407268827697<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.13300029994067813\",\"0.25645897317655214\",\"0.6105407268827697\"],\"textposition\":\"outside\",\"texttemplate\":\"%{text:.2f}\",\"x\":[0.13300029994067813,0.25645897317655214,0.6105407268827697],\"y\":[\"optimizer\",\"lr\",\"dropout\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('6d569937-2c16-4158-adeb-c8800a53fa10');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from optuna.trial import TrialState\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "    \n",
    "fig = optuna.visualization.plot_param_importances(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "5qRtbTtz8vs4"
   },
   "source": [
    "## Recomendaciones finales\n",
    "\n",
    "* No es necesario realizar la búsqueda de hiperparámetros sobre el conjunto de datos entero, ni entrenar el clasificador durante todas las epocas hasta que comienza a diverger. Se puede utilizar para encontrar los espacios más prometedores de valores posibles, y luego realizar una segunda búsqueda con con menos iteraciones pero con el proceso de entrenamiento completo.\n",
    "* No realizar la búsqueda utilizando notebooks, sino scripts.\n",
    "* Combinar Optuna con mlflow para un registro de los resultados ordenado.\n",
    "* Modificar el training loop para guardar los modelos para no tener que reentrenar el modelo de mejores parámetros."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "8_automated_hyperparameter_search.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
