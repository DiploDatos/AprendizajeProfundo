{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DiploDatos/AprendizajeProfundo/blob/master/8_automated_hyperparameter_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qy2yUgKC8vsg"
   },
   "source": [
    "# Búsqueda de Hiperparámetros\n",
    "\n",
    "Las redes neuronales tienen decenas de hiperparámetros que afectan su arquitectura y proceso de entrenamiento. Más aún, el desempeño final del modelo está condicionado a encontar un conjunto de valores para dichos hiperparámetros exitosos, para una inicialización aleatoria de los pesos dada. Por ello, la exploración de hiperparámetros se vuelve una de las partes más tediosas y críticas del entrenamiento de redes neuronales. Para obtener resultados que sean correctos, significativos y reproducibles es necesario planificar y sistemizar este proceso de búsqueda.\n",
    "\n",
    "  >  hyper-parameter optimization should be regarded as a formal outer loop in the learning process\n",
    "\n",
    "Formalmente, este proceso se puede describir como la minimización de la función de pérdida (o maximizar la performance) como si fuera una función de *caja negra* que toma como parámetros los valores de los hiperparámetros:\n",
    "\n",
    "$$ f(\\theta) = loss_\\theta(y, \\hat{y}) $$\n",
    "$$ \\theta^* = argmin_\\theta f(\\theta) $$\n",
    "\n",
    "donde $\\theta$ es el conjunto de hiperparámetros del modelo, $loss$ es la pérdida generada entre las etiquetas verdaderas $y$ y las etiquetas generadas por el modelo $\\hat{y}$, y $f$ es la función objetivo de la minimización.\n",
    "\n",
    "\n",
    "Las estrategias principales para la exploración del espacio de hiperparámetros son:\n",
    "* Búsqueda manual, donde un humano define los valores de cada hiperparámetro.\n",
    "* Búsqueda por grilla o *grid search*, donde se define un conjunto de valores posibles que puede tomar cada hiperparámetro, y se realiza un experimento por cada combinación posible.\n",
    "* Búsqueda aleatoria o *random search*, donde se define un rango de valores posibles para cada hiperparámetro, y se elige al azar un valor del rango para cada experimento.\n",
    "* Búsqueda automátizada, *automated search* o *model-based search*, que es igual a la búsqueda aleatoria pero la selección del valor de cada hiperparámetro está condicionado por los resultados de experimentos anteriores. Para más información ver el paper [*Algorithms for Hyper-Parameter Optimization*](https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf)\n",
    "\n",
    "En la siguiente imagen, tomada del paper [*Random Search for Hyper-Parameter Optimization*](https://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf), se muestra el impacto de las primeras dos estrategias para un hiperparámetro con alta influencia en el desempeño del modelo final, y otro que sin influencia. No solo require muchas evaluaciones para lograr cobertura, sino que las combinaciones en dónde sólo se varían hiperparámetros no relevantes no recolectan información nueva. El éxito de la búsqueda por grilla depende de que el nivel de granularidad de la grilla cubra adecuadamente los valores relevantes, que son desconocidos a priori.\n",
    "\n",
    "![Comparación de las exploraciones entre grid search y random search](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1531340388/grid_vs_random_jltknd.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZnHi2iN7BiA"
   },
   "source": [
    "Para solucionar todos estos problemas, es que se utiliza la **exploración bayesiana**. Este método modela la loss como un Gaussian process, y tiene en cuenta los resultados de los experimentos anteriores para ir construyendo una distribución de probabilidad de la pérdida dados los hiperparámetros:\n",
    "\n",
    "$$ P(loss | \\theta)$$\n",
    "\n",
    "Para elegir una nueva combinación de hiperparámetros a probar dados los experimentos previos, el algoritmo utiliza una *surrogate function* para aproximar el comportamiento de la pérdida y una *selection function* basada en la mejora esperada. A grandes rasgos, el algoritmo sigue los siguientes pasos:\n",
    "\n",
    "  1. Encontrar el mejor conjunto de hiperparámetros que maximize la mejora esperada (EI), estimada a través de la *surrogate function*.\n",
    "  2. Calcular la performance del modelo con la combinación de hiperparámetros elegida. Esto corresponde a evaluar la función objetivo.\n",
    "  3. Actualizar la forma de la *surrogate function* utilizando el teorema de Bayes para que se ajuste mejor a la verdadera distribución $ P(loss | \\theta)$\n",
    "\n",
    "Afortunadamente, muchos algoritmos de búsqueda están implementados y funcionan como cajas negras. Veremos un ejemplo utilizando la librería hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hUunZMB_gk2",
    "outputId": "c0ec776a-249a-4b43-9ce3-d5a974c46c5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "# If running in colab, you need to update gensim\n",
    "# !pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "VJmgwjm48vso"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import functools\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tempfile\n",
    "import seaborn\n",
    "\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.parsing import preprocessing\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from tqdm.notebook import tqdm, trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "t0XhsOvd_nbC",
    "outputId": "8de096c8-c530-4861-b94b-9e3835af99b9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'4.1.2'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure version 4.X\n",
    "import gensim\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUzR6Nfv8vsp"
   },
   "source": [
    "## Parte 1: Preprocesamiento del texto\n",
    "\n",
    "Primero leeremos el dataset como se explica en la notebook 5_cnns.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "sLySwHxR-l2W"
   },
   "outputs": [],
   "source": [
    "# If necessary, download data\n",
    "# %%bash\n",
    "# mkdir data\n",
    "# curl -L https://cs.famaf.unc.edu.ar/\\~ccardellino/resources/diplodatos/glove.6B.50d.txt.gz -o ./data/glove.6B.50d.txt.gz\n",
    "# curl -L https://cs.famaf.unc.edu.ar/\\~ccardellino/resources/diplodatos/imdb_reviews.csv.gz -o ./data/imdb_reviews.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "bVdiWbML8vsq"
   },
   "outputs": [],
   "source": [
    "class IMDBReviewsDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if torch.is_tensor(item):\n",
    "            item = item.to_list()\n",
    "        \n",
    "        item = {\n",
    "            \"data\": self.dataset.loc[item, \"review\"],\n",
    "            \"target\": self.dataset.loc[item, \"sentiment\"]\n",
    "        }\n",
    "        \n",
    "        if self.transform:\n",
    "            item = self.transform(item)\n",
    "        \n",
    "        return item\n",
    "\n",
    "class RawDataProcessor:\n",
    "    def __init__(self, \n",
    "                 dataset, \n",
    "                 ignore_header=True, \n",
    "                 filters=None, \n",
    "                 vocab_size=50000):\n",
    "        if filters:\n",
    "            self.filters = filters\n",
    "        else:\n",
    "            self.filters = [\n",
    "                lambda s: s.lower(),\n",
    "                preprocessing.strip_tags,\n",
    "                preprocessing.strip_punctuation,\n",
    "                preprocessing.strip_multiple_whitespaces,\n",
    "                preprocessing.strip_numeric,\n",
    "                preprocessing.remove_stopwords,\n",
    "                preprocessing.strip_short,\n",
    "            ]\n",
    "        \n",
    "        # Create dictionary based on all the reviews (with corresponding preprocessing)\n",
    "        self.dictionary = corpora.Dictionary(\n",
    "            dataset[\"review\"].map(self._preprocess_string).tolist()\n",
    "        )\n",
    "        # Filter the dictionary and compactify it (make the indices continous)\n",
    "        self.dictionary.filter_extremes(no_below=2, no_above=1, keep_n=vocab_size)\n",
    "        self.dictionary.compactify()\n",
    "        # Add a couple of special tokens\n",
    "        self.dictionary.patch_with_special_tokens({\n",
    "            \"[PAD]\": 0,\n",
    "            \"[UNK]\": 1\n",
    "        })\n",
    "        self.idx_to_target = sorted(dataset[\"sentiment\"].unique())\n",
    "        self.target_to_idx = {t: i for i, t in enumerate(self.idx_to_target)}\n",
    "\n",
    "    def _preprocess_string(self, string):\n",
    "        return preprocessing.preprocess_string(string, filters=self.filters)\n",
    "\n",
    "    def _sentence_to_indices(self, sentence):\n",
    "        return self.dictionary.doc2idx(sentence, unknown_word_index=1)\n",
    "    \n",
    "    def encode_data(self, data):\n",
    "        return self._sentence_to_indices(self._preprocess_string(data))\n",
    "    \n",
    "    def encode_target(self, target):\n",
    "        return self.target_to_idx[target]\n",
    "    \n",
    "    def __call__(self, item):\n",
    "        if isinstance(item[\"data\"], str):\n",
    "            data = self.encode_data(item[\"data\"])\n",
    "        else:\n",
    "            data = [self.encode_data(d) for d in item[\"data\"]]\n",
    "        \n",
    "        if isinstance(item[\"target\"], str):\n",
    "            target = self.encode_target(item[\"target\"])\n",
    "        else:\n",
    "            target = [self.encode_target(t) for t in item[\"target\"]]\n",
    "        \n",
    "        return {\n",
    "            \"data\": data,\n",
    "            \"target\": target,\n",
    "            \"sentence\": item[\"data\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N38F6o3VAYSD"
   },
   "source": [
    "### Separando el conjunto de validación o *dev*\n",
    "\n",
    "En deep learning, es **MUY** importante utilizar un conjunto de validación durante la búsqueda de hiperparámetros, que puede ser tomado de la partición de entrenamiento. Esto es independiente de la estrategia de búsqueda que se utilice.\n",
    "\n",
    "De esta manera, se previene el overfitting indirecto y se cuenta con una partición de datos nunca antes vista para poder evaluar la generalización real del modelo a datos no vistos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "fdxy4poX_8_3"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/imdb_reviews.csv.gz\")\n",
    "preprocess = RawDataProcessor(dataset)\n",
    "train_indices, test_indices = train_test_split(dataset.index, test_size=0.2, random_state=42)\n",
    "train_indices, dev_indices = train_test_split(train_indices, test_size=0.2, random_state=42)\n",
    "train_dataset = IMDBReviewsDataset(dataset.loc[train_indices].reset_index(drop=True), transform=preprocess)\n",
    "dev_dataset = IMDBReviewsDataset(dataset.loc[dev_indices].reset_index(drop=True), transform=preprocess)\n",
    "# We won't use test_dataset until the end!\n",
    "test_dataset = IMDBReviewsDataset(dataset.loc[test_indices].reset_index(drop=True), transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "gemdFTfO8ELO"
   },
   "outputs": [],
   "source": [
    "class PadSequences:\n",
    "    def __init__(self, pad_value=0, max_length=100):\n",
    "        self.pad_value = pad_value\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, items):\n",
    "        data, target = list(zip(*[(item[\"data\"], item[\"target\"]) for item in items]))\n",
    "        seq_lengths = [len(d) for d in data]\n",
    "\n",
    "        max_length = self.max_length\n",
    "        seq_lengths = [min(self.max_length, l) for l in seq_lengths]\n",
    "\n",
    "        data = [d[:l] + [self.pad_value] * (max_length - l)\n",
    "                for d, l in zip(data, seq_lengths)]\n",
    "            \n",
    "        return {\n",
    "            \"data\": torch.LongTensor(data),\n",
    "            \"target\": torch.FloatTensor(target)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPpIPlkr8vsx"
   },
   "source": [
    "## Parte 2: Esqueleto de la red neuronal\n",
    "\n",
    "Definimos el modelo a entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "tq6C63l-8vsy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "LVWbyNkq8vsz"
   },
   "outputs": [],
   "source": [
    "class ImdbLSTM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 pretrained_embeddings_path, dictionary, embedding_size,\n",
    "                 hidden_layer=32,\n",
    "                 num_layers=1, dropout=0., bias=True,\n",
    "                 bidirectional=False,\n",
    "                 freeze_embedings=True):\n",
    "        \n",
    "        super(ImdbLSTM, self).__init__()\n",
    "        output_size = 1\n",
    "        # Create the Embeddings layer and add pre-trained weights\n",
    "        embeddings_matrix = torch.randn(len(dictionary), embedding_size)\n",
    "        embeddings_matrix[0] = torch.zeros(embedding_size)\n",
    "        with gzip.open(pretrained_embeddings_path, \"rt\") as fh:\n",
    "            for line in fh:\n",
    "                word, vector = line.strip().split(None, 1)\n",
    "                if word in dictionary.token2id:\n",
    "                    embeddings_matrix[dictionary.token2id[word]] =\\\n",
    "                        torch.FloatTensor([float(n) for n in vector.split()])\n",
    "        self.embedding_config = {'freeze': freeze_embedings,\n",
    "                                  'padding_idx': 0}\n",
    "        self.embeddings = nn.Embedding.from_pretrained(\n",
    "            embeddings_matrix, **self.embedding_config)\n",
    "        \n",
    "        # Set our LSTM parameters\n",
    "        self.lstm_config = {'input_size': embedding_size,\n",
    "                            'hidden_size': hidden_layer,\n",
    "                            'num_layers': num_layers,\n",
    "                            'bias': bias,\n",
    "                            'batch_first': True,\n",
    "                            'dropout': dropout if num_layers > 1 else 0.0,\n",
    "                            'bidirectional': bidirectional}\n",
    "        \n",
    "        # Set our fully connected layer parameters\n",
    "        self.linear_config = {'in_features': hidden_layer,\n",
    "                              'out_features': output_size,\n",
    "                              'bias': bias}\n",
    "        \n",
    "        # Instanciate the layers\n",
    "        self.lstm = nn.LSTM(**self.lstm_config)\n",
    "        self.droupout_layer = nn.Dropout(dropout)\n",
    "        self.classification_layer = nn.Linear(**self.linear_config)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        emb = self.embeddings(inputs)\n",
    "        lstm_out, _ = self.lstm(emb)\n",
    "        # Take last state of lstm, which is a representation of\n",
    "        # the entire text\n",
    "        lstm_out = lstm_out[:, -1, :].squeeze()\n",
    "        lstm_out = self.droupout_layer(lstm_out)\n",
    "        predictions = self.activation(self.classification_layer(lstm_out))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ej4JfQx57nmw"
   },
   "source": [
    "Encapsularemos el algoritmo de entrenamiento dentro de una función parametrizable. La función debería devolver los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "JO279TL-2BMr"
   },
   "outputs": [],
   "source": [
    "# Some default values\n",
    "EPOCHS = 2\n",
    "MAX_SEQUENCE_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "LHnG8wj07mX-"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_imbd_model(train_dataset, dev_dataset,\n",
    "                     pretrained_embeddings_path, dictionary, embedding_size,\n",
    "                     batch_size=128, max_sequence_len=MAX_SEQUENCE_LEN,\n",
    "                     hidden_layer=32, dropout=0.,\n",
    "                     epochs=EPOCHS, lr=0.001, optimizer_class=optim.Adam,\n",
    "                     verbose=False):\n",
    "\n",
    "    if verbose:\n",
    "        print_fn = print\n",
    "    else:\n",
    "        print_fn = lambda *x: None\n",
    "    # We define again the data loaders since this code could run in\n",
    "    # parallel\n",
    "    pad_sequeces = PadSequences(max_length=max_sequence_len)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                              collate_fn=pad_sequeces, drop_last=False)\n",
    "    dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False,\n",
    "                            collate_fn=pad_sequeces, drop_last=False)\n",
    "\n",
    "    # We are not going to explore all hyperparameters, only this ones.\n",
    "    model = ImdbLSTM(pretrained_embeddings_path, dictionary, embedding_size,\n",
    "                     hidden_layer=hidden_layer, dropout=dropout)\n",
    "\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer = optimizer_class(model.parameters(), lr)\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'test_loss': [],\n",
    "        'test_avp': []\n",
    "    }\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = []\n",
    "        print_fn(\"Epoch\", epoch)\n",
    "        for idx, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch[\"data\"])\n",
    "            loss_value = loss_function(output.squeeze(), batch[\"target\"])\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            running_loss.append(loss_value.item())\n",
    "        train_loss = sum(running_loss) / len(running_loss)\n",
    "        print_fn(\"\\t Final train_loss\", train_loss)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        running_loss = []\n",
    "        targets = []\n",
    "        predictions = []\n",
    "        for batch in dev_loader:\n",
    "            output = model(batch[\"data\"])\n",
    "            running_loss.append(\n",
    "                loss_function(output.squeeze(), batch[\"target\"]).item()\n",
    "            )\n",
    "            targets.extend(batch[\"target\"].numpy())\n",
    "            # Round up model output to get the predictions.\n",
    "            # What would happen if you change the activation to tanh?\n",
    "            predictions.extend(output.squeeze().round().detach().numpy())\n",
    "        test_loss = sum(running_loss) / len(running_loss)\n",
    "        avp = metrics.average_precision_score(targets, predictions)\n",
    "        print_fn(\"\\t Final test_loss\", test_loss)\n",
    "        print_fn(\"\\t Final test_avp\", avp)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_avp'].append(avp)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WEzziR8j8vs0",
    "outputId": "d0f4e0b4-8646-4234-d4b3-19492be26298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\t Final train_loss 0.6751024463176727\n",
      "\t Final test_loss 0.61183714488196\n",
      "\t Final test_avp 0.6281198166028745\n",
      "Epoch 1\n",
      "\t Final train_loss 0.633317717552185\n",
      "\t Final test_loss 0.6387771065272982\n",
      "\t Final test_avp 0.606606246189802\n"
     ]
    }
   ],
   "source": [
    "history = train_imbd_model(\n",
    "    train_dataset, dev_dataset,\n",
    "    pretrained_embeddings_path=\"./data/glove.6B.50d.txt.gz\",\n",
    "    dictionary=preprocess.dictionary, embedding_size=50, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDw_sn_E8vs1"
   },
   "source": [
    "## Utilizando hyperopt\n",
    "\n",
    "Para utilizar alguno de los algoritmos de hyperopt, es necesario definir una función objetivo que será minimizada. Esta función recibe un objeto con los valores para los hiperparámetros de cada experimento, y debe devolver una única métrica (o un diccionario con la clave `key` asociada a dicha métrica). En nuestro caso, utilizaremos el *average precision score* obtenido en el conjunto de validación.\n",
    "\n",
    "Les recomendamos consultar el [Tutorial oficial](https://github.com/hyperopt/hyperopt/wiki/FMin) para más detalles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "G6-fXTPFDcLZ"
   },
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "# define an objective function\n",
    "def objective_fn(args):\n",
    "    print(\"Exploring config:\", args)\n",
    "    # These references a train_dataset and dev_dataset are\n",
    "    # taken from the globa context!\n",
    "    history = train_imbd_model(\n",
    "        train_dataset, dev_dataset,\n",
    "        pretrained_embeddings_path=\"./data/glove.6B.50d.txt.gz\",\n",
    "        dictionary=preprocess.dictionary, embedding_size=50,\n",
    "        **args)\n",
    "\n",
    "    # This is the value that will be minimized!\n",
    "    history['loss'] = history['test_avp'][-1] * -1\n",
    "    # These are required keys\n",
    "    history['status'] = STATUS_OK\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2pgRRblWEYfQ",
    "outputId": "fc89f7e0-1f84-47bd-c436-b77cb1a64d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring config:\n",
      "{'dropout': 0.2890479374892883, 'lr': 0.0005619877136798918, 'optimizer_class': <class 'torch.optim.rmsprop.RMSprop'>}\n",
      "Exploring config:\n",
      "{'dropout': 0.22131831673195007, 'lr': 0.0035044337243026304, 'optimizer_class': <class 'torch.optim.rmsprop.RMSprop'>}\n",
      "Exploring config:\n",
      "{'dropout': 0.16934105885114742, 'lr': 0.0012099599557950811, 'optimizer_class': <class 'torch.optim.rmsprop.RMSprop'>}\n",
      "Exploring config:\n",
      "{'dropout': 0.06450308716808428, 'lr': 0.0030574777969635137, 'optimizer_class': <class 'torch.optim.rmsprop.RMSprop'>}\n",
      "Exploring config:\n",
      "{'dropout': 0.08330933039456134, 'lr': 0.003857283414022462, 'optimizer_class': <class 'torch.optim.adam.Adam'>}\n",
      "Exploring config:\n",
      "{'dropout': 0.19663182522919626, 'lr': 0.001568002467096589, 'optimizer_class': <class 'torch.optim.rmsprop.RMSprop'>}\n",
      "Exploring config:\n",
      "{'dropout': 0.2192367141768013, 'lr': 0.0003081939607931429, 'optimizer_class': <class 'torch.optim.adam.Adam'>}\n",
      "Exploring config:\n",
      "{'dropout': 0.19390887091523412, 'lr': 0.00079518470412425, 'optimizer_class': <class 'torch.optim.adam.Adam'>}\n",
      "Exploring config:\n",
      "{'dropout': 0.22475927346854213, 'lr': 0.00428516049482644, 'optimizer_class': <class 'torch.optim.adam.Adam'>}\n",
      "Exploring config:\n",
      "{'dropout': 0.18053770187940094, 'lr': 0.002566814013223315, 'optimizer_class': <class 'torch.optim.rmsprop.RMSprop'>}\n",
      "100%|██████████| 10/10 [10:57<00:00, 65.77s/it, best loss: -0.6508734734714676]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "\n",
    "# define a search space\n",
    "space = {\n",
    "    'lr': hp.loguniform('lr', numpy.log(0.0001), numpy.log(0.005)),  # see appendix\n",
    "    'optimizer_class': hp.choice(\n",
    "        'optimizer_class', [optim.Adam, optim.RMSprop]),\n",
    "    'dropout': hp.uniform('dropout', 0, 0.5)\n",
    "}\n",
    "\n",
    "# define the Trials object, which will allow us to store\n",
    "# information from every experiment.\n",
    "trials = Trials()\n",
    "# minimize the objective over the space\n",
    "best = fmin(objective_fn, space, algo=tpe.suggest, max_evals=10, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9LqRPCMxlZGy",
    "outputId": "80b80d84-5e13-4421-8764-fd71f84f5180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{'dropout': 0.19390887091523412, 'lr': 0.00079518470412425, 'optimizer_class': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters:\")\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mnMwhPRbuGOJ",
    "outputId": "284cbf8f-d3ca-406f-b7c1-8de55a9add38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': -0.6472116252490916,\n",
       "  'status': 'ok',\n",
       "  'test_avp': [0.6298830395202307, 0.6472116252490916],\n",
       "  'test_loss': [0.6231811595341515, 0.6022195655202108],\n",
       "  'train_loss': [0.6613753888607025, 0.6232913773059845]},\n",
       " {'loss': -0.5825253111624369,\n",
       "  'status': 'ok',\n",
       "  'test_avp': [0.5570784351195028, 0.5825253111624369],\n",
       "  'test_loss': [0.6419762978478084, 0.682945452039204],\n",
       "  'train_loss': [0.6596087901592255, 0.6519552345275879]},\n",
       " {'loss': -0.5834746334182055,\n",
       "  'status': 'ok',\n",
       "  'test_avp': [0.5207418398111484, 0.5834746334182055],\n",
       "  'test_loss': [0.6910244841424246, 0.6574282494802324],\n",
       "  'train_loss': [0.688560727596283, 0.6731955027580261]},\n",
       " {'loss': -0.6223613829607744,\n",
       "  'status': 'ok',\n",
       "  'test_avp': [0.6442822059600711, 0.6223613829607744],\n",
       "  'test_loss': [0.6372423228763399, 0.6369397640228271],\n",
       "  'train_loss': [0.6727170276641846, 0.6677722644805908]},\n",
       " {'loss': -0.6169903615258416,\n",
       "  'status': 'ok',\n",
       "  'test_avp': [0.6345135779514864, 0.6169903615258416],\n",
       "  'test_loss': [0.6176432087307885, 0.6397115635493446],\n",
       "  'train_loss': [0.675246896982193, 0.6748301792144775]},\n",
       " {'loss': -0.5699691356352947,\n",
       "  'status': 'ok',\n",
       "  'test_avp': [0.5147286123683854, 0.5699691356352947],\n",
       "  'test_loss': [0.6925196590877715, 0.6729281800133842],\n",
       "  'train_loss': [0.6788727715015411, 0.6869417538642884]},\n",
       " {'loss': -0.5677109943360636,\n",
       "  'status': 'ok',\n",
       "  'test_avp': [0.5198614917910236, 0.5677109943360636],\n",
       "  'test_loss': [0.6904571330736554, 0.6960669112583947],\n",
       "  'train_loss': [0.6926844131946563, 0.6728136169910431]},\n",
       " {'loss': -0.6508734734714676,\n",
       "  'status': 'ok',\n",
       "  'test_avp': [0.619127035397385, 0.6508734734714676],\n",
       "  'test_loss': [0.6405688476940942, 0.6011667478652227],\n",
       "  'train_loss': [0.6862278208732605, 0.6446535315513611]},\n",
       " {'loss': -0.572053695571806,\n",
       "  'status': 'ok',\n",
       "  'test_avp': [0.5628348582929037, 0.572053695571806],\n",
       "  'test_loss': [0.6691116510875641, 0.6516883704397414],\n",
       "  'train_loss': [0.68389759349823, 0.6793638138771058]},\n",
       " {'loss': -0.5256167879775777,\n",
       "  'status': 'ok',\n",
       "  'test_avp': [0.5994907882346505, 0.5256167879775777],\n",
       "  'test_loss': [0.6437215379306248, 0.6835636789836581],\n",
       "  'train_loss': [0.6746287696361541, 0.672327210187912]}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see the results of each experiment with the trials object.\n",
    "trials.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "5qRtbTtz8vs4"
   },
   "source": [
    "## Recomendaciones finales\n",
    "\n",
    "* Es recomendable utilizar un parámetro de *paciencia*, que corta el ciclo de entrenamiento cuando no detecta mejoras en el desempeño sobre el conjunto de validación por n cantidad de épocas. Esto ayudaría a evitar que el modelo sobreajuste.\n",
    "* Realizar una búsqueda de grilla previa para determinar los valores para el optimizador, learning rate, batch size y número de épocas mínimas de entrenamiento, ya que estos son hiperparámetros muy determinantes.\n",
    "* No es necesario realizar la búsqueda de hiperparámetros sobre el conjunto de datos entero, ni entrenar el clasificador durante todas las epocas hasta que comienza a diverger. Se puede utilizar para encontrar los espacios más prometedores de valores posibles, y luego realizar una segunda búsqueda con con menos iteraciones pero con el proceso de entrenamiento completo.\n",
    "* No realizar la búsqueda utilizando notebooks, sino scripts.\n",
    "* Combinar hyperopt con mlflow para un registro de los resultados ordenado.\n",
    "* Modificar el bucle de entrenamiento para guardar el último modelo con las mejores métricas en el conjunto de validación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WyMiSm8E8vs6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmioKhtgpJ5Q"
   },
   "source": [
    "## Apéndice: hp.loguniform\n",
    "\n",
    "Según la documentación oficial, la distribución `hp.loguniform`:\n",
    "* Returns a value drawn according to exp(uniform(low, high)) so that the logarithm of the return value is uniformly distributed.\n",
    "* When optimizing, this variable is constrained to the interval [exp(low), exp(high)].\n",
    "\n",
    "Supongamos que queremos que nuestros valores de lr se distribuyan logaritmicamente en el intervalo [0.0001, 0.005], entonces los valores de low y high deberían ser: log(0.0001) y  log(0.005). Veamos qué distribución de muestras obtenemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "qz51g-LZpd-X"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "aNUSEDBnpgDu",
    "outputId": "a57dd260-824f-4b76-8972-d44fe9cbbeba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f5ae3419610>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "low = numpy.log(0.0001)\n",
    "high = numpy.log(0.005)\n",
    "sample_size = 1000\n",
    "sample = numpy.exp(numpy.random.uniform(low, high, size=sample_size))\n",
    "seaborn.displot(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRiAOsncqBGz",
    "outputId": "81701624-3642-4b80-b141-e25ab6073a82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.004980610232365855, 0.00010016665752302445)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.max(), sample.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gO_gw22KqVmS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "8_automated_hyperparameter_search.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
