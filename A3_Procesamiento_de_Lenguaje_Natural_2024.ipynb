{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiploDatos/AprendizajeProfundo/blob/add_2024_content/A3_Procesamiento_de_Lenguaje_Natural_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch torchtext\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxioWbiuOFdl",
        "outputId": "2ee4199c-b431-4637-cad6-9c1e4c2fcb07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.26.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUt3tyaVBjTO"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from gensim import models\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer,WordNetLemmatizer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "import gensim.downloader as api\n",
        "\n",
        "#import torchtext\n",
        "#from torchtext.vocab import GloVe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0K1xyKMa7av",
        "outputId": "f6f58bf6-0b17-4905-ecae-225881a5809a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package snowball_data to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "nltk.download('punkt') #Descargamos el tokenizador llamado punkt\n",
        "nltk.download(\"stopwords\") # Descargamos las stop words\n",
        "nltk.download('snowball_data') # Algoritmo Porter para stemming version 2\n",
        "nltk.download('wordnet') # Necesaria para la Lematization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "RLZa859_YddK",
        "outputId": "d0973768-2160-4889-907f-a03b2736fa6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nNatural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics.\\nIt is primarily concerned with giving computers the ability to support and manipulate speech.\\nIt involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "text_example =\"\"\"\n",
        "Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics.\n",
        "It is primarily concerned with giving computers the ability to support and manipulate speech.\n",
        "It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches.\"\"\"\n",
        "text_example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmGpDpw9buKb"
      },
      "source": [
        "## Tokenizacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avHLMZF2Z56o",
        "outputId": "bebca7d6-e20c-4c1f-99ae-70e8239fedc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nNatural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics.',\n",
              " 'It is primarily concerned with giving computers the ability to support and manipulate speech.',\n",
              " 'It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e.',\n",
              " 'statistical and, most recently, neural network-based) machine learning approaches.']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "sentences_lst = sent_tokenize(text_example)\n",
        "sentences_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jVxQSg-atPq",
        "outputId": "62726df9-da55-449c-ea95-bea15d85d541"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " '(',\n",
              " 'NLP',\n",
              " ')',\n",
              " 'is',\n",
              " 'an',\n",
              " 'interdisciplinary',\n",
              " 'subfield',\n",
              " 'of',\n",
              " 'computer',\n",
              " 'science',\n",
              " 'and',\n",
              " 'linguistics',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'primarily',\n",
              " 'concerned',\n",
              " 'with',\n",
              " 'giving',\n",
              " 'computers',\n",
              " 'the',\n",
              " 'ability',\n",
              " 'to',\n",
              " 'support',\n",
              " 'and',\n",
              " 'manipulate',\n",
              " 'speech',\n",
              " '.',\n",
              " 'It',\n",
              " 'involves',\n",
              " 'processing',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'datasets',\n",
              " ',',\n",
              " 'such',\n",
              " 'as',\n",
              " 'text',\n",
              " 'corpora',\n",
              " 'or',\n",
              " 'speech',\n",
              " 'corpora',\n",
              " ',',\n",
              " 'using',\n",
              " 'either',\n",
              " 'rule-based',\n",
              " 'or',\n",
              " 'probabilistic',\n",
              " '(',\n",
              " 'i.e',\n",
              " '.',\n",
              " 'statistical',\n",
              " 'and',\n",
              " ',',\n",
              " 'most',\n",
              " 'recently',\n",
              " ',',\n",
              " 'neural',\n",
              " 'network-based',\n",
              " ')',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'approaches',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "words_lst = word_tokenize(text_example)\n",
        "words_lst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f81zhZoVb2tn"
      },
      "source": [
        "## Stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeJ7V7rYbQ9n",
        "outputId": "627b3a6d-9e6c-4e37-9f3c-737cbce0fb12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de stop words en ingles: 179\n",
            "Algunos ejemplos: [\"should've\", 'himself', 'being', 'at', 'nor', 'from', 'as', 'haven', 'ain', 'any', 'hasn', 'll', \"shouldn't\", 'a', 'up', 'is', 'or', 'ours', 'down', 'do']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download(\"stopwords\") # Descargamos las stop words\n",
        "stop_words_english = set(stopwords.words(\"english\"))\n",
        "print(f\"Cantidad de stop words en ingles: {len(stop_words_english)}\")\n",
        "print(f\"Algunos ejemplos: {list(stop_words_english)[:20]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KRDcdtSc5Vz",
        "outputId": "a8601957-6659-4442-ab61-929d4a1dac53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de stop words en español: 313\n",
            "Algunos ejemplos: ['mías', 'habrían', 'vuestras', 'hay', 'fuesen', 'una', 'este', 'tendrías', 'estuviste', 'tendrán', 'ni', 'fueron', 'estas', 'antes', 'teníais', 'son', 'tuviera', 'vosotros', 'hubieron', 'suya']\n"
          ]
        }
      ],
      "source": [
        "stop_words_spanish = set(stopwords.words(\"spanish\"))\n",
        "print(f\"Cantidad de stop words en español: {len(stop_words_spanish)}\")\n",
        "print(f\"Algunos ejemplos: {list(stop_words_spanish)[:20]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1s7DRjbdQO2",
        "outputId": "9df6ee5a-e96d-4535-cfc1-c76416ff32ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de palabras iniciales: 67\n",
            "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'an', 'interdisciplinary', 'subfield', 'of', 'computer', 'science', 'and', 'linguistics', '.', 'It', 'is', 'primarily', 'concerned', 'with', 'giving', 'computers', 'the', 'ability', 'to', 'support', 'and', 'manipulate', 'speech', '.', 'It', 'involves', 'processing', 'natural', 'language', 'datasets', ',', 'such', 'as', 'text', 'corpora', 'or', 'speech', 'corpora', ',', 'using', 'either', 'rule-based', 'or', 'probabilistic', '(', 'i.e', '.', 'statistical', 'and', ',', 'most', 'recently', ',', 'neural', 'network-based', ')', 'machine', 'learning', 'approaches', '.']\n",
            "\n",
            "\n",
            "Cantidad de palabras luego de remover stop words: 50\n",
            "['Natural', 'language', 'processing', '(', 'NLP', ')', 'interdisciplinary', 'subfield', 'computer', 'science', 'linguistics', '.', 'primarily', 'concerned', 'giving', 'computers', 'ability', 'support', 'manipulate', 'speech', '.', 'involves', 'processing', 'natural', 'language', 'datasets', ',', 'text', 'corpora', 'speech', 'corpora', ',', 'using', 'either', 'rule-based', 'probabilistic', '(', 'i.e', '.', 'statistical', ',', 'recently', ',', 'neural', 'network-based', ')', 'machine', 'learning', 'approaches', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words_spanish = set(stopwords.words(\"english\"))\n",
        "filtered_list_eng = []\n",
        "for word in words_lst:\n",
        "  # casefold es una manera de trabajar indistintamente mayusculas y minusculas\n",
        "  # ya que las stop words están todas en minúscula\n",
        "   if word.casefold() not in stop_words_english:\n",
        "        filtered_list_eng.append(word)\n",
        "\n",
        "print(f\"Cantidad de palabras iniciales: {len(words_lst)}\")\n",
        "print(words_lst)\n",
        "print('\\n')\n",
        "print(f\"Cantidad de palabras luego de remover stop words: {len(filtered_list_eng)}\")\n",
        "print(filtered_list_eng)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgCW4kJmer6r"
      },
      "source": [
        "**Ejercicio:** Hacer el mismo proceso partiendo de un texto ejemplo en español."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBFme-5WgrOj"
      },
      "source": [
        "## Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qsnPtvy5_Rx"
      },
      "outputs": [],
      "source": [
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_lst[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTlRmQeHP4mH",
        "outputId": "c695f533-9324-4ffe-a1dc-8d03cd11744f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " '(',\n",
              " 'NLP',\n",
              " ')',\n",
              " 'is',\n",
              " 'an',\n",
              " 'interdisciplinary',\n",
              " 'subfield']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXo-pso5ejwJ",
        "outputId": "a05acacd-536a-4f8b-e20b-6564e25780b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['natur',\n",
              " 'languag',\n",
              " 'process',\n",
              " '(',\n",
              " 'nlp',\n",
              " ')',\n",
              " 'is',\n",
              " 'an',\n",
              " 'interdisciplinari',\n",
              " 'subfield',\n",
              " 'of',\n",
              " 'comput',\n",
              " 'scienc',\n",
              " 'and',\n",
              " 'linguist']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "stemmed_words = [stemmer.stem(word) for word in words_lst]\n",
        "stemmed_words[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWaLthhvhfPm",
        "outputId": "2e1d41d7-7cf6-44cf-b2b9-042c0614f22a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original word: Discovery\n",
            "Stemmed word: discoveri\n",
            "--------\n",
            "Original word: discovered\n",
            "Stemmed word: discov\n",
            "--------\n",
            "Original word: discoveries\n",
            "Stemmed word: discoveri\n",
            "--------\n",
            "Original word: Discovering\n",
            "Stemmed word: discov\n",
            "--------\n"
          ]
        }
      ],
      "source": [
        "examples_words = ['Discovery'\t,'discovered'\t,'discoveries'\t,'Discovering']\n",
        "#examples_words = ['play'\t,'played'\t,'plays'\t,'playing']\n",
        "for word in examples_words:\n",
        "  print(f\"Original word: {word}\")\n",
        "  print(f\"Stemmed word: {stemmer.stem(word)}\")\n",
        "  print('--------')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RgEHXX86gyp"
      },
      "source": [
        "Veamos si hay algún cambio en el resultado cambiando el algoritmo de stemming..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lWCrCDLlRJf",
        "outputId": "6035daae-e982-4740-f00e-123a23b3c159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original word: Discovery\n",
            "Stemmed word: discoveri\n",
            "--------\n",
            "Original word: discovered\n",
            "Stemmed word: discov\n",
            "--------\n",
            "Original word: discoveries\n",
            "Stemmed word: discoveri\n",
            "--------\n",
            "Original word: Discovering\n",
            "Stemmed word: discov\n",
            "--------\n"
          ]
        }
      ],
      "source": [
        "stemmer = SnowballStemmer(\"english\")\n",
        "examples_words = ['Discovery'\t,'discovered'\t,'discoveries'\t,'Discovering']\n",
        "for word in examples_words:\n",
        "  print(f\"Original word: {word}\")\n",
        "  print(f\"Stemmed word: {stemmer.stem(word)}\")\n",
        "  print('--------')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH08jtuHkDLe"
      },
      "source": [
        "## Lemmatizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEEBymLrikNJ",
        "outputId": "c977a9f2-0288-40f5-e191-bf063eb4b00b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original word: discovery\n",
            "Stemmed word: discovery\n",
            "--------\n",
            "Original word: disco\n",
            "Stemmed word: disco\n",
            "--------\n",
            "Original word: discoveries\n",
            "Stemmed word: discovery\n",
            "--------\n",
            "Original word: discovering\n",
            "Stemmed word: discovering\n",
            "--------\n"
          ]
        }
      ],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "examples_words = ['discovery'\t,'disco'\t,'discoveries'\t,'discovering']\n",
        "for word in examples_words:\n",
        "  print(f\"Original word: {word}\")\n",
        "  print(f\"Stemmed word: {lemmatizer.lemmatize(word)}\")\n",
        "  print('--------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uC1sEFfKp-qh",
        "outputId": "18066142-2cc2-47bc-da20-e618fa1206a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'worst'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "lemmatizer.lemmatize(\"worst\") #Por defecto toma considera \"nouns\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldiZPPehrFX8"
      },
      "source": [
        "El parametro `pos` es por defecto `'n'` donde `n` está asociado a `noun`. Sin embargo, para asegurarnos que `\"worst\"` sea tratado como un adjetivo  necesitamos cambiar el parámetro por defecto a `pos=\"a\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bHyZmo5Sq6E9",
        "outputId": "6efd78ae-2ad7-4184-b078-b1a3800f0aa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "lemmatizer.lemmatize(\"worst\", pos=\"a\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7K6-kyfNe5z"
      },
      "source": [
        "## Bag of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swkJm5sCNeoP"
      },
      "outputs": [],
      "source": [
        "new_text_example = \"\"\"\n",
        "In 2003, word n-gram model, at the time the best statistical algorithm, was overperformed by a multi-layer perceptron (with a single hidden layer and context length of several words trained on up to 14 million of words with a CPU cluster in language modelling) by Yoshua Bengio with co-authors.[8]\n",
        "\n",
        "In 2010, Tomáš Mikolov (then a PhD student at Brno University of Technology) with co-authors applied a simple recurrent neural network with a single hidden layer to language modelling,=[9] and in the following years he went on to develop Word2vec. In the 2010s, representation learning and deep neural network-style (featuring many hidden layers) machine learning methods became widespread in natural language processing.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7JlpnPAq94x",
        "outputId": "2c71351c-b837-418c-aced-d2a8d44b22c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nIn 2003, word n-gram model, at the time the best statistical algorithm, was overperformed by a multi-layer perceptron (with a single hidden layer and context length of several words trained on up to 14 million of words with a CPU cluster in language modelling) by Yoshua Bengio with co-authors.',\n",
              " '[8]\\n\\nIn 2010, Tomáš Mikolov (then a PhD student at Brno University of Technology) with co-authors applied a simple recurrent neural network with a single hidden layer to language modelling,=[9] and in the following years he went on to develop Word2vec.',\n",
              " 'In the 2010s, representation learning and deep neural network-style (featuring many hidden layers) machine learning methods became widespread in natural language processing.']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "sentences = sent_tokenize(new_text_example)\n",
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfklQnkcOeky",
        "outputId": "ab5c997e-0216-4e43-f73a-0d79074329cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "len(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEAK1IS4OOki",
        "outputId": "9f838e8c-9d31-4131-e3f1-402ab2468b12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "        1, 0, 1, 2, 1, 2, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 2, 1,\n",
              "        1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 2, 0, 1, 1, 0, 1, 0, 1, 1,\n",
              "        0, 0, 3, 1, 0, 2, 0, 1],\n",
              "       [0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
              "        0, 1, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
              "        0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 2, 1, 0, 1, 0, 0,\n",
              "        1, 0, 2, 0, 1, 0, 1, 0],\n",
              "       [0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "        0, 0, 1, 2, 1, 0, 1, 2, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "X = count_vectorizer.fit_transform(sentences)\n",
        "X = X.toarray()\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1yJOFiNPVHe",
        "outputId": "f620d5c0-8b8a-47b5-acaa-7c082c5ae0bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 74)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcDwC2RROhP-",
        "outputId": "a3f9752d-b555-44e1-f83b-2518afd75dc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['in', '2003', 'word', 'gram', 'model', 'at', 'the', 'time', 'best', 'statistical', 'algorithm', 'was', 'overperformed', 'by', 'multi', 'layer', 'perceptron', 'with', 'single', 'hidden', 'and', 'context', 'length', 'of', 'several', 'words', 'trained', 'on', 'up', 'to', '14', 'million', 'cpu', 'cluster', 'language', 'modelling', 'yoshua', 'bengio', 'co', 'authors', '2010', 'tomáš', 'mikolov', 'then', 'phd', 'student', 'brno', 'university', 'technology', 'applied', 'simple', 'recurrent', 'neural', 'network', 'following', 'years', 'he', 'went', 'develop', 'word2vec', '2010s', 'representation', 'learning', 'deep', 'style', 'featuring', 'many', 'layers', 'machine', 'methods', 'became', 'widespread', 'natural', 'processing'])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "count_vectorizer.vocabulary_.keys()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn-e5rPrOnKi",
        "outputId": "2ab0b075-84c8-4642-ad7e-5cca98109edf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "        0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
              "        0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "        0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
              "        1, 0, 1, 0, 1, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
              "        1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "count_vectorizer2 = CountVectorizer(ngram_range=(2,2))\n",
        "X2 = count_vectorizer2.fit_transform(sentences)\n",
        "X2 = X2.toarray()\n",
        "X2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWBR0svPPROT",
        "outputId": "71a9a676-5123-4cce-c260-4d873f1cb937"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 98)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "X2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DnVd7EuPIxd",
        "outputId": "c3fd3a60-198e-4977-b7cc-3925b92dcdd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['14 million',\n",
              " '2003 word',\n",
              " '2010 tomáš',\n",
              " '2010s representation',\n",
              " 'algorithm was',\n",
              " 'and context',\n",
              " 'and deep',\n",
              " 'and in',\n",
              " 'applied simple',\n",
              " 'at brno',\n",
              " 'at the',\n",
              " 'authors applied',\n",
              " 'became widespread',\n",
              " 'bengio with',\n",
              " 'best statistical',\n",
              " 'brno university',\n",
              " 'by multi',\n",
              " 'by yoshua',\n",
              " 'cluster in',\n",
              " 'co authors',\n",
              " 'context length',\n",
              " 'cpu cluster',\n",
              " 'deep neural',\n",
              " 'develop word2vec',\n",
              " 'featuring many',\n",
              " 'following years',\n",
              " 'gram model',\n",
              " 'he went',\n",
              " 'hidden layer',\n",
              " 'hidden layers',\n",
              " 'in 2003',\n",
              " 'in 2010',\n",
              " 'in language',\n",
              " 'in natural',\n",
              " 'in the',\n",
              " 'language modelling',\n",
              " 'language processing',\n",
              " 'layer and',\n",
              " 'layer perceptron',\n",
              " 'layer to',\n",
              " 'layers machine',\n",
              " 'learning and',\n",
              " 'learning methods',\n",
              " 'length of',\n",
              " 'machine learning',\n",
              " 'many hidden',\n",
              " 'methods became',\n",
              " 'mikolov then',\n",
              " 'million of',\n",
              " 'model at',\n",
              " 'modelling and',\n",
              " 'modelling by',\n",
              " 'multi layer',\n",
              " 'natural language',\n",
              " 'network style',\n",
              " 'network with',\n",
              " 'neural network',\n",
              " 'of several',\n",
              " 'of technology',\n",
              " 'of words',\n",
              " 'on to',\n",
              " 'on up',\n",
              " 'overperformed by',\n",
              " 'perceptron with',\n",
              " 'phd student',\n",
              " 'recurrent neural',\n",
              " 'representation learning',\n",
              " 'several words',\n",
              " 'simple recurrent',\n",
              " 'single hidden',\n",
              " 'statistical algorithm',\n",
              " 'student at',\n",
              " 'style featuring',\n",
              " 'technology with',\n",
              " 'the 2010s',\n",
              " 'the best',\n",
              " 'the following',\n",
              " 'the time',\n",
              " 'then phd',\n",
              " 'time the',\n",
              " 'to 14',\n",
              " 'to develop',\n",
              " 'to language',\n",
              " 'tomáš mikolov',\n",
              " 'trained on',\n",
              " 'university of',\n",
              " 'up to',\n",
              " 'was overperformed',\n",
              " 'went on',\n",
              " 'widespread in',\n",
              " 'with co',\n",
              " 'with cpu',\n",
              " 'with single',\n",
              " 'word gram',\n",
              " 'words trained',\n",
              " 'words with',\n",
              " 'years he',\n",
              " 'yoshua bengio']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "sorted(count_vectorizer2.vocabulary_.keys())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbKGOvL1QVkg"
      },
      "source": [
        "## TF- IDF\n",
        "\n",
        "La intuición detrás de esto es que cuanto más común es una palabra en todos los documentos, menor es su importancia para el documento actual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOPMSOsLPPaA",
        "outputId": "5bc79755-62e2-48a7-f417-f368ea75bd7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nIn 2003, word n-gram model, at the time the best statistical algorithm, was overperformed by a multi-layer perceptron (with a single hidden layer and context length of several words trained on up to 14 million of words with a CPU cluster in language modelling) by Yoshua Bengio with co-authors.',\n",
              " '[8]\\n\\nIn 2010, Tomáš Mikolov (then a PhD student at Brno University of Technology) with co-authors applied a simple recurrent neural network with a single hidden layer to language modelling,=[9] and in the following years he went on to develop Word2vec.',\n",
              " 'In the 2010s, representation learning and deep neural network-style (featuring many hidden layers) machine learning methods became widespread in natural language processing.']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVb3G5-cU9NL"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "transformed = tfidf.fit_transform(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformed[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jICZySf_Utir",
        "outputId": "ad7f9953-73ea-4c8a-c38b-962b150f5218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x74 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 40 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMNaqRzSU9n9",
        "outputId": "0695bbb8-7607-4ba2-a03b-0a94484f7157"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "df = pd.DataFrame(transformed[0].T.todense(),\n",
        "    \tindex=tfidf.get_feature_names_out(), columns=[\"TF-IDF\"])\n",
        "df = df.sort_values('TF-IDF', ascending=False)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "L1Fnh03OVN7C",
        "outputId": "2bc39703-dcca-4154-f5bf-964c89584a2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              TF-IDF\n",
              "with        0.326879\n",
              "words       0.286538\n",
              "by          0.286538\n",
              "layer       0.217920\n",
              "of          0.217920\n",
              "...              ...\n",
              "tomáš       0.000000\n",
              "university  0.000000\n",
              "word2vec    0.000000\n",
              "he          0.000000\n",
              "recurrent   0.000000\n",
              "\n",
              "[74 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de19f8b9-d147-42c1-8367-0d796388026a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TF-IDF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>with</th>\n",
              "      <td>0.326879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>words</th>\n",
              "      <td>0.286538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>by</th>\n",
              "      <td>0.286538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>layer</th>\n",
              "      <td>0.217920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>of</th>\n",
              "      <td>0.217920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tomáš</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>university</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word2vec</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>he</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recurrent</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de19f8b9-d147-42c1-8367-0d796388026a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de19f8b9-d147-42c1-8367-0d796388026a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de19f8b9-d147-42c1-8367-0d796388026a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-07231fda-bced-41c4-9912-861225c584a5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-07231fda-bced-41c4-9912-861225c584a5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-07231fda-bced-41c4-9912-861225c584a5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 74,\n  \"fields\": [\n    {\n      \"column\": \"TF-IDF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08405625778775014,\n        \"min\": 0.0,\n        \"max\": 0.3268792850056334,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.2865379851290707,\n          0.10895976166854446,\n          0.3268792850056334\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df.sort_values(by=['TF-IDF'], ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHFsOuF8_sQ7"
      },
      "source": [
        "## Embeddings\n",
        "\n",
        "Algunos links interesantes:\n",
        "\n",
        "- https://ronxin.github.io/wevi/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyJG2G_aYNJo"
      },
      "source": [
        "### Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0gKmJiraFsX",
        "outputId": "82fd1219-d95c-43b1-def8-da9be7744758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "/root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n"
          ]
        }
      ],
      "source": [
        "path = api.load(\"word2vec-google-news-300\", return_path=True)\n",
        "print(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmyghCjKYzdB"
      },
      "outputs": [],
      "source": [
        "w2v = models.KeyedVectors.load_word2vec_format('/root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1yR9WW6bWlI",
        "outputId": "9a28cd51-281d-4ef6-eaf4-fd8326ecfb0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300,)\n",
            "[ 1.66015625e-01 -8.20312500e-02  4.51171875e-01  1.22558594e-01\n",
            "  1.34765625e-01  1.33789062e-01 -3.88671875e-01 -3.66210938e-02\n",
            "  5.15625000e-01  1.04003906e-01  1.82617188e-01 -1.66015625e-01\n",
            "  2.00195312e-01  2.12890625e-01 -1.90429688e-02  8.74023438e-02\n",
            " -7.75146484e-03 -2.87109375e-01 -1.54296875e-01 -3.86718750e-01\n",
            "  2.15820312e-01  2.04101562e-01 -3.14453125e-01 -4.00390625e-01\n",
            "  2.57812500e-01  3.17382812e-02  5.73730469e-03  1.16699219e-01\n",
            "  2.20703125e-01  1.01074219e-01 -1.53320312e-01 -3.83300781e-02\n",
            "  1.38549805e-02  9.22851562e-02 -1.68457031e-02  2.27539062e-01\n",
            "  1.07421875e-01 -2.43164062e-01 -9.81445312e-02  3.49609375e-01\n",
            "  1.97265625e-01 -1.80664062e-01 -4.27246094e-02 -2.09960938e-01\n",
            "  1.14257812e-01  4.37500000e-01  1.00585938e-01  5.22460938e-02\n",
            " -1.41601562e-02  1.16210938e-01  1.32446289e-02  2.73437500e-01\n",
            " -1.41906738e-03  3.30078125e-01 -8.34960938e-02 -2.49023438e-01\n",
            " -1.33789062e-01 -1.84570312e-01  8.59375000e-02  2.48046875e-01\n",
            " -1.74804688e-01  4.02343750e-01 -1.24023438e-01 -3.22265625e-02\n",
            "  1.56250000e-01  7.35473633e-03  1.30859375e-01  2.16064453e-02\n",
            " -1.14257812e-01  2.24609375e-02  1.59179688e-01 -9.96093750e-02\n",
            "  1.59179688e-01  3.00781250e-01 -3.39843750e-01  1.73339844e-02\n",
            "  8.93554688e-02  8.15429688e-02 -2.49023438e-01 -3.75976562e-02\n",
            "  2.46582031e-02  7.17773438e-02 -1.95312500e-01  3.54003906e-02\n",
            "  2.80380249e-04  1.16210938e-01 -2.49023438e-01  2.22656250e-01\n",
            " -1.65039062e-01  1.06201172e-02  2.01171875e-01 -3.99780273e-03\n",
            " -1.86523438e-01 -1.34765625e-01 -1.22070312e-01 -7.66601562e-02\n",
            "  2.47070312e-01  7.91015625e-02  1.42578125e-01  2.69531250e-01\n",
            "  5.27343750e-02  6.44531250e-02 -9.66796875e-02 -1.55273438e-01\n",
            " -1.70898438e-02  5.76171875e-02  8.49609375e-02 -6.68945312e-02\n",
            " -1.70898438e-02 -9.08203125e-02  2.55859375e-01 -5.76171875e-02\n",
            " -1.16210938e-01 -3.22265625e-02  5.27343750e-02 -1.03759766e-02\n",
            " -3.22265625e-02 -2.00195312e-01  1.01562500e-01  9.08203125e-02\n",
            " -3.16406250e-01  1.81640625e-01  8.05664062e-03  1.11816406e-01\n",
            " -1.92382812e-01 -1.97265625e-01 -8.44726562e-02 -3.90625000e-01\n",
            " -5.88378906e-02  4.80957031e-02 -1.78710938e-01 -1.22558594e-01\n",
            " -2.45117188e-01 -1.50390625e-01 -1.51367188e-01 -3.80859375e-01\n",
            "  1.06445312e-01 -2.14843750e-01 -1.33666992e-02 -1.30859375e-01\n",
            " -9.76562500e-02 -1.75781250e-01  8.49609375e-02  1.61132812e-01\n",
            "  1.76757812e-01 -3.45703125e-01 -1.09375000e-01  5.24902344e-02\n",
            "  2.28271484e-02 -1.45507812e-01 -1.44042969e-02 -1.41601562e-01\n",
            " -2.50000000e-01  3.47656250e-01 -1.15234375e-01 -1.91406250e-01\n",
            " -9.91210938e-02 -6.03027344e-02  2.45361328e-02 -3.66210938e-02\n",
            " -1.98242188e-01 -8.54492188e-02  7.08007812e-02 -3.92578125e-01\n",
            "  7.17773438e-02  1.69921875e-01 -4.85839844e-02 -1.53320312e-01\n",
            " -1.22558594e-01  1.70898438e-01  4.39453125e-02 -1.58203125e-01\n",
            " -5.63964844e-02  1.80664062e-01  1.62109375e-01 -1.07421875e-01\n",
            "  1.31835938e-01  1.04980469e-01  1.55273438e-01 -1.31835938e-02\n",
            " -2.23388672e-02 -1.82617188e-01  7.72094727e-03 -1.06201172e-02\n",
            " -3.78906250e-01  1.72851562e-01 -2.87109375e-01  2.47070312e-01\n",
            "  1.19018555e-02  2.41210938e-01 -3.27148438e-02  1.79687500e-01\n",
            "  5.15136719e-02  2.08007812e-01 -6.10351562e-03 -3.08227539e-03\n",
            "  5.66406250e-02 -1.34887695e-02 -3.33984375e-01 -2.61718750e-01\n",
            "  6.83593750e-02  2.96875000e-01  4.71191406e-02 -6.92749023e-03\n",
            "  2.99072266e-02  1.16210938e-01 -9.47265625e-02 -2.50000000e-01\n",
            "  7.81250000e-03 -3.01513672e-02 -1.48437500e-01 -5.93261719e-02\n",
            "  2.55859375e-01  7.66601562e-02 -9.32617188e-02 -1.39648438e-01\n",
            " -6.83593750e-02 -7.95898438e-02  2.06054688e-01 -1.31835938e-01\n",
            " -1.43554688e-01  2.73437500e-01 -1.75781250e-01  6.93359375e-02\n",
            "  4.44335938e-02 -9.03320312e-02 -3.73535156e-02  4.90722656e-02\n",
            " -2.20703125e-01  7.91015625e-02 -1.27929688e-01  2.50000000e-01\n",
            "  1.38671875e-01  2.14843750e-01  1.07910156e-01  1.45507812e-01\n",
            " -3.12500000e-02 -2.11914062e-01 -8.78906250e-03  1.44042969e-02\n",
            "  2.49023438e-01  1.33789062e-01  5.73730469e-02 -3.98437500e-01\n",
            " -1.42578125e-01  7.71484375e-02  3.30078125e-01 -1.21582031e-01\n",
            " -1.58203125e-01 -2.94921875e-01  2.31933594e-02 -9.03320312e-02\n",
            "  6.25000000e-02 -2.94189453e-02  9.17968750e-02 -3.33984375e-01\n",
            " -8.10546875e-02  2.65625000e-01 -8.39843750e-02 -2.96875000e-01\n",
            " -1.73828125e-01  1.88476562e-01  2.85156250e-01  2.63671875e-01\n",
            "  1.00097656e-01  9.86328125e-02 -1.98242188e-01 -7.51953125e-02\n",
            " -1.47460938e-01  9.61914062e-02 -1.13281250e-01  1.43554688e-01\n",
            "  6.49414062e-02  1.63085938e-01 -1.30859375e-01 -8.74023438e-02\n",
            " -1.70898438e-01  9.91210938e-02 -8.44726562e-02 -1.88446045e-03\n",
            "  4.68750000e-02  9.66796875e-02  1.19140625e-01  6.83593750e-02\n",
            " -1.36718750e-01 -8.30078125e-03 -1.21582031e-01  4.94384766e-03\n",
            " -2.55126953e-02 -3.34167480e-03 -1.28906250e-01 -9.03320312e-02\n",
            " -6.59179688e-02  1.40625000e-01 -1.37695312e-01 -1.73828125e-01\n",
            " -4.84375000e-01 -1.50390625e-01  9.13085938e-02  1.63085938e-01]\n"
          ]
        }
      ],
      "source": [
        "vect = w2v['worst']\n",
        "print(vect.shape)\n",
        "print(vect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRRUtcXIbZQz",
        "outputId": "b1582234-d048-4989-e9bf-30e6aaa18aec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Worst', 0.6146091818809509),\n",
              " ('weakest', 0.6143776774406433),\n",
              " ('scariest', 0.5957257747650146),\n",
              " ('ugliest', 0.5931181311607361),\n",
              " ('best', 0.5835111141204834),\n",
              " ('bleakest', 0.5718506574630737),\n",
              " ('strongest', 0.567145586013794),\n",
              " ('nastiest', 0.5644308924674988),\n",
              " ('lousiest', 0.563145101070404),\n",
              " ('toughest', 0.5624396204948425)]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "w2v.most_similar('worst')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irIj12ogbfCM",
        "outputId": "226a836e-4591-43d5-985e-53eeb1d2be5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.word2vec.Word2Vec at 0x7a65b07c13c0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "sentences = [sent for sent in sentences]\n",
        "custom_model = models.Word2Vec(sentences, min_count=1,workers=4)\n",
        "custom_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pd5G73vyd-UU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Supongamos que tienes una lista de oraciones donde cada oración es una lista de palabras.\n",
        "sentences = [[\"esto\", \"es\", \"una\", \"oración\"], [\"esto\", \"es\", \"otra\", \"oración\"]]\n",
        "\n",
        "# Entrenar un modelo Word2Vec\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, sg=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQeWga2G-9zo",
        "outputId": "67d5802f-b3f2-41dd-ea30-f92725605819"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9.4563962e-05,  3.0773198e-03, -6.8126451e-03, -1.3754654e-03,\n",
              "        7.6685809e-03,  7.3464094e-03, -3.6732971e-03,  2.6427018e-03,\n",
              "       -8.3171297e-03,  6.2054861e-03, -4.6373224e-03, -3.1641065e-03,\n",
              "        9.3113566e-03,  8.7338570e-04,  7.4907029e-03, -6.0740625e-03,\n",
              "        5.1605068e-03,  9.9228229e-03, -8.4573915e-03, -5.1356913e-03,\n",
              "       -7.0648370e-03, -4.8626517e-03, -3.7785638e-03, -8.5361991e-03,\n",
              "        7.9556061e-03, -4.8439382e-03,  8.4236134e-03,  5.2625705e-03,\n",
              "       -6.5500261e-03,  3.9578713e-03,  5.4701497e-03, -7.4265362e-03,\n",
              "       -7.4057197e-03, -2.4752307e-03, -8.6257253e-03, -1.5815723e-03,\n",
              "       -4.0343284e-04,  3.2996845e-03,  1.4418805e-03, -8.8142155e-04,\n",
              "       -5.5940580e-03,  1.7303658e-03, -8.9737179e-04,  6.7936908e-03,\n",
              "        3.9735902e-03,  4.5294715e-03,  1.4343059e-03, -2.6998555e-03,\n",
              "       -4.3668128e-03, -1.0320747e-03,  1.4370275e-03, -2.6460087e-03,\n",
              "       -7.0737829e-03, -7.8053069e-03, -9.1217868e-03, -5.9351693e-03,\n",
              "       -1.8474245e-03, -4.3238713e-03, -6.4606704e-03, -3.7173224e-03,\n",
              "        4.2891586e-03, -3.7390434e-03,  8.3781751e-03,  1.5339935e-03,\n",
              "       -7.2423196e-03,  9.4337985e-03,  7.6312125e-03,  5.4932819e-03,\n",
              "       -6.8488456e-03,  5.8226790e-03,  4.0090932e-03,  5.1853694e-03,\n",
              "        4.2559016e-03,  1.9397545e-03, -3.1701624e-03,  8.3538452e-03,\n",
              "        9.6121803e-03,  3.7926030e-03, -2.8369951e-03,  7.1275235e-06,\n",
              "        1.2188185e-03, -8.4583247e-03, -8.2239453e-03, -2.3101569e-04,\n",
              "        1.2372875e-03, -5.7433806e-03, -4.7252737e-03, -7.3460746e-03,\n",
              "        8.3286157e-03,  1.2129784e-04, -4.5093987e-03,  5.7017053e-03,\n",
              "        9.1800150e-03, -4.0998720e-03,  7.9646818e-03,  5.3754342e-03,\n",
              "        5.8791232e-03,  5.1259040e-04,  8.2130842e-03, -7.0190406e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# Obtener el embedding de una palabra\n",
        "embedding = model.wv[\"esto\"]\n",
        "embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah6OfI-3_yqG"
      },
      "source": [
        "### Glove\n",
        "\n",
        "Algunos links útiles:\n",
        "\n",
        "\n",
        "- https://notebook.community/spro/practical-pytorch/glove-word-vectors/glove-word-vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ejOys0aAtpE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "42cd4fa2-13e0-4f77-b87e-cb3425ee8732"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'vocab' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-d4e152ca418f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGloVe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'6B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loaded {} words'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
          ]
        }
      ],
      "source": [
        "glove = vocab.GloVe(name='6B', dim=100)\n",
        "\n",
        "print('Loaded {} words'.format(len(glove.itos)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSjLIiQZAvsM"
      },
      "outputs": [],
      "source": [
        "def get_word(word):\n",
        "    return glove.vectors[glove.stoi[word]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyRpKdUrAyry"
      },
      "outputs": [],
      "source": [
        "def closest(vec, n=10):\n",
        "    \"\"\"\n",
        "    Find the closest words for a given vector\n",
        "    \"\"\"\n",
        "    all_dists = [(w, torch.dist(vec, get_word(w))) for w in glove.itos]\n",
        "    return sorted(all_dists, key=lambda t: t[1])[:n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ufy6i2eA1A6"
      },
      "outputs": [],
      "source": [
        "def print_tuples(tuples):\n",
        "    for tuple in tuples:\n",
        "        print('(%.4f) %s' % (tuple[1], tuple[0]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_word('google')"
      ],
      "metadata": {
        "id": "Wpr2uuTpWArR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJQXhs5iA3Eo"
      },
      "outputs": [],
      "source": [
        "print_tuples(closest(get_word('google')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0pUX-PbA73J"
      },
      "outputs": [],
      "source": [
        "print_tuples(closest(get_word('science')))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c7nBh3W7q84v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}