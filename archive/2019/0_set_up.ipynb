{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - Part 0\n",
    "\n",
    "This notebook explains how to install all the preriquistes and libraries that you will need to run the following tutorials. If you can execute all the following cells, you are good to go.\n",
    "\n",
    "## Environment configuration\n",
    "\n",
    "\n",
    "### Install conda\n",
    "\n",
    "There are two major package managers in Python: pip and conda. For this tutorial we will be using conda which, besides being a package manager is also useful as a version manager. There are two main ways to install conda: Anaconda and Miniconda. Any will be useful for this course, just follow instructions here, according to your operative system:\n",
    "\n",
    "https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html#regular-installation\n",
    "\n",
    "### Create an environment with all the Anaconda libraries\n",
    "\n",
    "    $ conda create --name deeplearning python=3.7 anaconda\n",
    "\n",
    "Don't forget to activate the new env\n",
    "\n",
    "    $ conda activate deeplearning    \n",
    "\n",
    "### Install TensorFlow\n",
    "\n",
    "We will use the [TensorFlow](https://www.tensorflow.org/) library to build and train models. In particular, we will use [Keras](https://www.tensorflow.org/guide/keras) module, which are simpler to implement and understand, at the cost of lossing flexibility when defining the architectures.\n",
    "\n",
    "In order to install tensorflow we recommend following the [official documentation](https://www.tensorflow.org/install). In your local machine, you will install the version that only has cpu support, but in Nabucodonosor you need to install the version with [GPU support](https://www.tensorflow.org/install/gpu).\n",
    "\n",
    "#### CPU\n",
    "\n",
    "Upgrade `pip` to the latest version:\n",
    "\n",
    "    (deeplearning) $ pip install --upgrade pip\n",
    "\n",
    "Install tensorflow:\n",
    "\n",
    "    (deeplearning) $ pip install --upgrade tensorflow\n",
    "    \n",
    "Then just check the version installed is 2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "#### GPU\n",
    "\n",
    "The supported version of Tensorlfow depends on the cuda drivers intalled on the machine. In the case of Nabucodonosor, cuda and cudnn libraries are located in the /opt directory. You can check the system has intalled cuda 10.X, and cuddnn >= 7.4.1, enough to intall tensorflow 2.0.\n",
    "\n",
    "    (deeplearning) $ pip install tensorflow-gpu\n",
    "\n",
    "**WARNING**: changes between tensorflow and keras versions are not minor and your code will break if you don't migrate. For example: https://www.tensorflow.org/beta/guide/effective_tf2\n",
    "\n",
    "Now we need to tell tensorflow where cuda is installed by setting the environment variable LD_LIBRARY_PATH\n",
    "\n",
    "    $ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/cuda/10.0/lib64:/opt/cudnn/v7.6-cu10.0/\n",
    "    $ export CUDA_HOME=/opt/cuda/10.0\n",
    "\n",
    "It is convenient to add this statement to your `~/.bashrc` file, so it is executed everytime you open a new console.\n",
    "\n",
    "To check if it works, execute the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install other libraries\n",
    "\n",
    "We need the `gensim` library to deal with word embeddings, so you need to install it. Plus, the `mlflow` tool to keep track of experiments. Also, for seeing a graphical representation of the Keras models, you need `graphviz` and `pydot`.\n",
    "\n",
    "\n",
    "```\n",
    "(deeplearning) $ pip install gensim mlflow\n",
    "(deeplearning) $ conda install graphviz python-graphviz pydot\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download embeddings and dataset\n",
    "\n",
    "### MNIST\n",
    "\n",
    "The dataset we will use (MNIST) will be downloaded by Keras automatically the first time you use it. To save time, you can download it now running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "df = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PetFinder Dataset\n",
    "\n",
    "For this course we will setup a Kaggle competition based on the same data for the course of \"Supervised Learning\". You can access the competition with [this link](https://www.kaggle.com/t/8842af91604944a9974bd6d5a3e097c5) and download the dataset (check the **Download All** button).\n",
    "\n",
    "Once you have the dataset downloaded in your machine you can copy it to `nabucodonosor` with the following command (this assumes you are already in the directory having the dataset):\n",
    "\n",
    "    $ scp diplodatos-deeplearning-2019.zip USERNAME@nabucodonosor.ccad.unc.edu.ar:./\n",
    "\n",
    "After that you should enter to nabucodonosor (via ssh) and unzip it like so:\n",
    "\n",
    "    $ unzip -d petfinder_dataset diplodatos-deeplearning-2019.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunneling and ssh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do you run a notebook in a remote machine?** You use an ssh connection with a port forwarding. This way, everything that goes to the port on the server machine (like a jupyter notebook) also goes to your localhost.\n",
    "\n",
    "It is likely that everyone will be using the same ports, so we recommend you to select a random number before connecting. The port on the ssh must be the same that you use to start the notebook.\n",
    "\n",
    "```\n",
    "$ ssh -L PORT:localhost:PORT USER@SERVER\n",
    "$ conda activate diplodatos\n",
    "(diplodatos) $ jupyter notebook --port PORT --no-browser\n",
    "```\n",
    "\n",
    "Now you can use the notebook as if it were running on your computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using slurm\n",
    "\n",
    "The Nabucodonosor server uses a queue system called slurm, which grants exclusive access to the CPU resources. You should enqueue everythin you do that takes more than 10 minutes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up\n",
    "\n",
    "1. Download the script https://raw.githubusercontent.com/MIREL-UNC/mirel-scripts/master/run_scripts/submit_job_slurm.sh\n",
    "\n",
    "2. Create a logs folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enqueue things\n",
    "\n",
    "To enqueue a job on slurm, first put your command in a file, for example command.txt\n",
    "```\n",
    "$ sbatch submit_job_slurm.sh commant.txt\n",
    "```\n",
    "\n",
    "The queue will assign your job a number JOBID. All the output of your process will be redirected to logs/JOBID.out and logs/JOBID.err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Controlling things\n",
    "\n",
    "To see the state of the queue run `$ squeue`\n",
    "\n",
    "To cancel a job run `$ scancel JOBID`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid using GPUs\n",
    "\n",
    "If all the GPUs are being used, you can still force Keras to use the CPU. For simple models this is still a very good option.\n",
    "\n",
    "The easiest way is to run set the environment variable  `CUDA_VISIBLE_DEVICES=\"\"` when running your commands. For example:\n",
    "\n",
    "```\n",
    "(diplodatos) $ CUDA_VISIBLE_DEVICES=\"\" jupyter notebook --no-browser\n",
    "(diplodatos) $ CUDA_VISIBLE_DEVICES=\"\" exercise_1.py --experiment_name mlp_200\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
