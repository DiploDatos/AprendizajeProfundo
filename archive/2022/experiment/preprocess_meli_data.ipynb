{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.parsing import preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = {\n",
    "    \"spanish\": stopwords.words(\"spanish\"),\n",
    "    \"portuguese\": stopwords.words(\"portuguese\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-service",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for language in tqdm([\"spanish\", \"portuguese\"]):\n",
    "    for split in tqdm([\"train\", \"test\", \"validation\"]):\n",
    "        df = pd.read_json(f\"../data/meli-challenge-2019/{language}.{split}.jsonl.gz\", lines=True)\n",
    "        data.append(df)\n",
    "\n",
    "data = pd.concat(data, ignore_index=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-spectacular",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_titles(row):\n",
    "    title = preprocessing.strip_tags(row[\"title\"].lower())\n",
    "    title = preprocessing.strip_punctuation(title)\n",
    "    title = preprocessing.strip_numeric(title)\n",
    "    title = word_tokenize(title, language=row[\"language\"])\n",
    "    title = [word for word in title if word not in stopwords[row[\"language\"]]]\n",
    "    title = [word for word in title if len(word) >= 3]\n",
    "    return title\n",
    "\n",
    "data[\"tokenized_title\"] = data.progress_apply(clean_titles, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "for language, lang_df in data.groupby([\"language\"]):\n",
    "    dictionary = corpora.Dictionary(lang_df[\"tokenized_title\"].tolist())\n",
    "    dictionary.filter_extremes(no_below=2, no_above=1, keep_n=50000)\n",
    "    dictionary.compactify()\n",
    "    dictionary.patch_with_special_tokens({\n",
    "        \"[PAD]\": 0,\n",
    "        \"[UNK]\": 1\n",
    "    })\n",
    "    \n",
    "    data.loc[lang_df.index, \"data\"] = lang_df[\"tokenized_title\"].progress_map(\n",
    "        lambda t: dictionary.doc2idx(\n",
    "            document=t,\n",
    "            unknown_word_index=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    label_to_target = {label: index for index, label in enumerate(lang_df[\"category\"].unique())}\n",
    "    data.loc[lang_df.index, \"target\"] = lang_df[\"category\"].progress_map(lambda l: label_to_target[l])\n",
    "    \n",
    "    with gzip.open(f\"../data/meli-challenge-2019/{language}_token_to_index.json.gz\", \"wt\") as fh:\n",
    "        json.dump(dictionary.token2id, fh)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = data.groupby([\"language\"])[\"target\"].max().to_dict()\n",
    "n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = data.groupby([\"language\", \"split\"]).size().to_dict()\n",
    "split_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"n_labels\"] = data.apply(lambda r: n_labels[r[\"language\"]] + 1, axis=1)\n",
    "data[\"size\"] = data.apply(lambda r: split_size[(r[\"language\"], r[\"split\"])], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (language, split), sub_df in data.groupby([\"language\", \"split\"]):\n",
    "    sub_df.to_json(\n",
    "        f\"../data/meli-challenge-2019/{language}.{split}.jsonl.gz\",\n",
    "        lines=True,\n",
    "        orient=\"records\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
