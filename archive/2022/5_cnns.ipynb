{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiploDatos/AprendizajeProfundo/blob/master/5_cnns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WAMkzi2jF5F"
      },
      "source": [
        "# Construyendo una red convolucional con PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpGbtqhyjF5H"
      },
      "source": [
        "## Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SgMX7x4jF5H",
        "outputId": "be8f50da-4062-4c22-9e7e-5407ac3d193e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/users/jfrau/miniconda3/envs/deeplearning/lib/python3.7/site-packages/botocore/vendored/requests/packages/urllib3/_collections.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
            "  from collections import Mapping, MutableMapping\n",
            "/users/jfrau/miniconda3/envs/deeplearning/lib/python3.7/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
            "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
            "  _deprecated()\n"
          ]
        }
      ],
      "source": [
        "import gzip\n",
        "import mlflow\n",
        "import numpy\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import tempfile\n",
        "\n",
        "from gensim import corpora\n",
        "from gensim.parsing import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, average_precision_score,confusion_matrix\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndqTFN4-jF5J"
      },
      "source": [
        "## Red convolucional para imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atOCl7WojF5J"
      },
      "source": [
        "### Datos del CIFAR-10\n",
        "\n",
        "Utilizamos los mismos datos que se usaron en el [notebook 1](https://github.com/DiploDatos/AprendizajeProfundo/blob/master/1_basic_mlp.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_3ScPbsjF5K",
        "outputId": "5bc56f47-1047-4e68-f8ab-33fb6f079c11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "CIFAR_CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', \n",
        "                 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 2\n",
        "transform = transforms.Compose( #Agrupa todas las transformaciones que le pedimos\n",
        "    [transforms.ToTensor(),      # en este caso, convertimos a tensores y normalizamos los datos\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "## Train\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', \n",
        "                                        train=True,\n",
        "                                        download=True, \n",
        "                                        transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, \n",
        "                                          batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, \n",
        "                                          num_workers=2)\n",
        "## Test\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', \n",
        "                                       train=False,\n",
        "                                       download=True, \n",
        "                                       transform=transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, \n",
        "                                         batch_size=BATCH_SIZE,\n",
        "                                         shuffle=False, \n",
        "                                         num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ryj92zWjF5K"
      },
      "source": [
        "### Red convolucional\n",
        "\n",
        "- La red convolucional se obtiene apilando capas [`torch.nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html). \n",
        "    - En particular, este tipo de capas acepta matrices (a diferencia de la lineal que sólo acepta vectores). En las capas se definen lo canales de entrada y los de salida, además del tamaño del kernel (i.e. ventana). \n",
        "- También son comunes las capas [`torch.nn.MaxPool2d`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) que realizan una operación de max pooling, en 2 dimensiones. \n",
        "- La red se completa con algunas capas lineales [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html?highlight=nn%20linear#torch.nn.Linear) para poder llevarla a las 10 dimensiones de salida que vienen a representar las clases.\n",
        "\n",
        "**Funciones auxiliares**:\n",
        "-  [`Tensor.view`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html?highlight=view#torch.Tensor.view): Es similar a [`reshape()`](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) de numpy, cambia las dimensiones de un tensor sin guardarlo en memoria y sin cambiar los valores del input original. El parámetro `-1` se usa cuando no sabemos cuántas filas queremos pero conocemos la cantidad de columnas (esto se extrapola a más dimensiones).\n",
        "- [`Optimizer.zero_grad`](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html#:~:text=Sets%20the%20gradients%20of%20all,set%20the%20grads%20to%20None.): En cada paso de entrenamiento necesitamos resetear los valores del gradiente para que no se cuenten \"2 veces\". Para mayor detalle visitar este [link](https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch#:~:text=384,of%20maximization%20objectives)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFm2gEsEjF5L",
        "outputId": "941c5010-a8f2-4148-ab88-da1a03bfc166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5) # (#canales de entrada, #canales de salida, #filtros)\n",
        "        self.pool = nn.MaxPool2d(2, 2) # (kernel_size , stride)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5) # (#canales de entrada, #canales de salida, #filtros)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # (input, output)\n",
        "        self.fc2 = nn.Linear(120, 84) # (input, output)\n",
        "        self.fc3 = nn.Linear(84, 10) # (input, output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x))) #Aplicamos relu a la primera capa convolucional, luego pooling\n",
        "        x = self.pool(F.relu(self.conv2(x))) #Aplicamos relu a la segunda capa convolucional, luego pooling\n",
        "        x = x.view(-1, 16 * 5 * 5) # Necesitamos transformarlo en un vector para que sea input de la capa lineal\n",
        "        x = F.relu(self.fc1(x)) # Finalmente relu a cada capa convolucional\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = CNN()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glc3AeCejF5M"
      },
      "source": [
        "### Entrenamiento\n",
        "\n",
        "La red se entrena igual que el caso del perceptrón multicapa, solo que esta vez no requiere reacomodar la matriz de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "cbaf6c321a6c4339b67bdda8db3f63c4",
            "5137f24eb96c4c23b135a48d4bc1735e",
            "897566bef8af4988aac9f61607a1a762"
          ]
        },
        "id": "gHxSqhQtjF5M",
        "outputId": "040c903c-17aa-4f83-8ba5-ff5cb3d15a47"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbaf6c321a6c4339b67bdda8db3f63c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5137f24eb96c4c23b135a48d4bc1735e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train loss: NaN:   0%|          | 0/391 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "897566bef8af4988aac9f61607a1a762",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train loss: NaN:   0%|          | 0/391 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "model.train()\n",
        "iters_per_epoch = len(trainloader)\n",
        "for epoch in trange(EPOCHS):  # loop over the dataset multiple times\n",
        "    pbar = tqdm(trainloader, desc=\"Train loss: NaN\")\n",
        "    for data in pbar:\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(f\"Train loss: {loss.item():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ67KAC0jF5M"
      },
      "source": [
        "### Evaluación\n",
        "\n",
        "Una vez más, la evaluación es similar al caso del perceptrón multicapa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ed8dfa44b5614920add216ff01336686"
          ]
        },
        "id": "NeLZrbsWjF5N",
        "outputId": "6bcbe299-6939-4063-b1ae-449b2b31bb1d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed8dfa44b5614920add216ff01336686",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       plane       0.61      0.49      0.54      1000\n",
            "         car       0.55      0.74      0.63      1000\n",
            "        bird       0.53      0.25      0.34      1000\n",
            "         cat       0.35      0.33      0.34      1000\n",
            "        deer       0.42      0.45      0.43      1000\n",
            "         dog       0.41      0.56      0.47      1000\n",
            "        frog       0.59      0.54      0.57      1000\n",
            "       horse       0.61      0.59      0.60      1000\n",
            "        ship       0.60      0.66      0.63      1000\n",
            "       truck       0.54      0.55      0.54      1000\n",
            "\n",
            "    accuracy                           0.52     10000\n",
            "   macro avg       0.52      0.52      0.51     10000\n",
            "weighted avg       0.52      0.52      0.51     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for data in tqdm(testloader):\n",
        "        inputs, labels = data\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        y_true.extend(labels.numpy())\n",
        "        y_pred.extend(predicted.numpy())\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=CIFAR_CLASSES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkSW-PYjjF5N"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame((confusion_matrix(y_true, y_pred)),columns=list(CIFAR_CLASSES),index=list(CIFAR_CLASSES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk_Ru6xGjF5N",
        "outputId": "d11ff701-af66-4bf6-dd37-525d8b791a55"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col0 {\n",
              "            background-color:  #008000;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col1 {\n",
              "            background-color:  #d0f3d0;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col2 {\n",
              "            background-color:  #c6eec6;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col3 {\n",
              "            background-color:  #dffcdf;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col4 {\n",
              "            background-color:  #d4f6d4;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col5 {\n",
              "            background-color:  #e0fce0;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col6 {\n",
              "            background-color:  #e1fde1;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col7 {\n",
              "            background-color:  #e3fee3;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col8 {\n",
              "            background-color:  #9dd79d;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col9 {\n",
              "            background-color:  #d3f5d3;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col0 {\n",
              "            background-color:  #dcfadc;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col1 {\n",
              "            background-color:  #008000;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col2 {\n",
              "            background-color:  #e5ffe5;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col3 {\n",
              "            background-color:  #e3fee3;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col4 {\n",
              "            background-color:  #e5ffe5;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col5 {\n",
              "            background-color:  #e5ffe5;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col6 {\n",
              "            background-color:  #e5ffe5;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col7 {\n",
              "            background-color:  #e5ffe5;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col8 {\n",
              "            background-color:  #d8f8d8;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col9 {\n",
              "            background-color:  #b4e4b4;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col0 {\n",
              "            background-color:  #c1ebc1;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col1 {\n",
              "            background-color:  #e0fce0;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col2 {\n",
              "            background-color:  #008000;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col3 {\n",
              "            background-color:  #a8dda8;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col4 {\n",
              "            background-color:  #84c984;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col5 {\n",
              "            background-color:  #aadeaa;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col6 {\n",
              "            background-color:  #c4edc4;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col7 {\n",
              "            background-color:  #d6f7d6;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col8 {\n",
              "            background-color:  #dffcdf;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col9 {\n",
              "            background-color:  #dffcdf;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col0 {\n",
              "            background-color:  #e0fce0;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col1 {\n",
              "            background-color:  #e1fde1;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col2 {\n",
              "            background-color:  #c7eec7;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col3 {\n",
              "            background-color:  #008000;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col4 {\n",
              "            background-color:  #c7eec7;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col5 {\n",
              "            background-color:  #6ebd6e;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col6 {\n",
              "            background-color:  #c3ecc3;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col7 {\n",
              "            background-color:  #d3f5d3;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col8 {\n",
              "            background-color:  #e0fce0;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col9 {\n",
              "            background-color:  #d0f3d0;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col0 {\n",
              "            background-color:  #d4f6d4;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col1 {\n",
              "            background-color:  #ddfbdd;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col2 {\n",
              "            background-color:  #b8e6b8;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col3 {\n",
              "            background-color:  #b9e7b9;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col4 {\n",
              "            background-color:  #008000;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col5 {\n",
              "            background-color:  #c2ebc2;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col6 {\n",
              "            background-color:  #bbe8bb;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col7 {\n",
              "            background-color:  #bfeabf;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col8 {\n",
              "            background-color:  #e1fde1;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col9 {\n",
              "            background-color:  #e5ffe5;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col0 {\n",
              "            background-color:  #e4fee4;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col1 {\n",
              "            background-color:  #e5ffe5;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col2 {\n",
              "            background-color:  #c4edc4;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col3 {\n",
              "            background-color:  #7bc47b;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col4 {\n",
              "            background-color:  #c5edc5;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col5 {\n",
              "            background-color:  #008000;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col6 {\n",
              "            background-color:  #d9f8d9;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col7 {\n",
              "            background-color:  #caf0ca;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col8 {\n",
              "            background-color:  #e2fde2;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col9 {\n",
              "            background-color:  #e5ffe5;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col0 {\n",
              "            background-color:  #e5ffe5;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col1 {\n",
              "            background-color:  #e2fde2;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col2 {\n",
              "            background-color:  #c3ecc3;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col3 {\n",
              "            background-color:  #89cc89;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col4 {\n",
              "            background-color:  #9cd69c;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col5 {\n",
              "            background-color:  #d7f7d7;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col6 {\n",
              "            background-color:  #008000;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col7 {\n",
              "            background-color:  #e3fee3;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col8 {\n",
              "            background-color:  #e5ffe5;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col9 {\n",
              "            background-color:  #e0fce0;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col0 {\n",
              "            background-color:  #defbde;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col1 {\n",
              "            background-color:  #e5ffe5;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col2 {\n",
              "            background-color:  #d6f7d6;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col3 {\n",
              "            background-color:  #c9efc9;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col4 {\n",
              "            background-color:  #c1ebc1;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col5 {\n",
              "            background-color:  #b0e1b0;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col6 {\n",
              "            background-color:  #e0fce0;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col7 {\n",
              "            background-color:  #008000;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col8 {\n",
              "            background-color:  #e5ffe5;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col9 {\n",
              "            background-color:  #d4f6d4;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col0 {\n",
              "            background-color:  #bbe8bb;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col1 {\n",
              "            background-color:  #c6eec6;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col2 {\n",
              "            background-color:  #defbde;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col3 {\n",
              "            background-color:  #e5ffe5;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col4 {\n",
              "            background-color:  #e4fee4;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col5 {\n",
              "            background-color:  #e1fde1;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col6 {\n",
              "            background-color:  #e5ffe5;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col7 {\n",
              "            background-color:  #e4fee4;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col8 {\n",
              "            background-color:  #008000;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col9 {\n",
              "            background-color:  #d3f5d3;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col0 {\n",
              "            background-color:  #dcfadc;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col1 {\n",
              "            background-color:  #9ed89e;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col2 {\n",
              "            background-color:  #e1fde1;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col3 {\n",
              "            background-color:  #e2fde2;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col4 {\n",
              "            background-color:  #e5ffe5;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col5 {\n",
              "            background-color:  #e3fee3;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col6 {\n",
              "            background-color:  #dffcdf;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col7 {\n",
              "            background-color:  #dbf9db;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col8 {\n",
              "            background-color:  #ccf1cc;\n",
              "            color:  #000000;\n",
              "        }    #T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col9 {\n",
              "            background-color:  #008000;\n",
              "            color:  #f1f1f1;\n",
              "        }</style><table id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >plane</th>        <th class=\"col_heading level0 col1\" >car</th>        <th class=\"col_heading level0 col2\" >bird</th>        <th class=\"col_heading level0 col3\" >cat</th>        <th class=\"col_heading level0 col4\" >deer</th>        <th class=\"col_heading level0 col5\" >dog</th>        <th class=\"col_heading level0 col6\" >frog</th>        <th class=\"col_heading level0 col7\" >horse</th>        <th class=\"col_heading level0 col8\" >ship</th>        <th class=\"col_heading level0 col9\" >truck</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7level0_row0\" class=\"row_heading level0 row0\" >plane</th>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col0\" class=\"data row0 col0\" >489</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col1\" class=\"data row0 col1\" >84</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col2\" class=\"data row0 col2\" >35</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col3\" class=\"data row0 col3\" >26</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col4\" class=\"data row0 col4\" >40</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col5\" class=\"data row0 col5\" >22</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col6\" class=\"data row0 col6\" >15</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col7\" class=\"data row0 col7\" >16</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col8\" class=\"data row0 col8\" >213</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row0_col9\" class=\"data row0 col9\" >60</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7level0_row1\" class=\"row_heading level0 row1\" >car</th>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col0\" class=\"data row1 col0\" >24</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col1\" class=\"data row1 col1\" >745</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col2\" class=\"data row1 col2\" >0</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col3\" class=\"data row1 col3\" >21</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col4\" class=\"data row1 col4\" >7</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col5\" class=\"data row1 col5\" >9</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col6\" class=\"data row1 col6\" >7</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col7\" class=\"data row1 col7\" >9</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col8\" class=\"data row1 col8\" >46</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row1_col9\" class=\"data row1 col9\" >132</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7level0_row2\" class=\"row_heading level0 row2\" >bird</th>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col0\" class=\"data row2 col0\" >82</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col1\" class=\"data row2 col1\" >33</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col2\" class=\"data row2 col2\" >252</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col3\" class=\"data row2 col3\" >100</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col4\" class=\"data row2 col4\" >193</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col5\" class=\"data row2 col5\" >152</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col6\" class=\"data row2 col6\" >83</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col7\" class=\"data row2 col7\" >48</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col8\" class=\"data row2 col8\" >26</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row2_col9\" class=\"data row2 col9\" >31</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7level0_row3\" class=\"row_heading level0 row3\" >cat</th>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col0\" class=\"data row3 col0\" >15</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col1\" class=\"data row3 col1\" >32</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col2\" class=\"data row3 col2\" >34</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col3\" class=\"data row3 col3\" >329</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col4\" class=\"data row3 col4\" >67</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col5\" class=\"data row3 col5\" >294</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col6\" class=\"data row3 col6\" >85</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col7\" class=\"data row3 col7\" >55</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col8\" class=\"data row3 col8\" >23</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row3_col9\" class=\"data row3 col9\" >66</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7level0_row4\" class=\"row_heading level0 row4\" >deer</th>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col0\" class=\"data row4 col0\" >40</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col1\" class=\"data row4 col1\" >42</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col2\" class=\"data row4 col2\" >50</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col3\" class=\"data row4 col3\" >77</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col4\" class=\"data row4 col4\" >446</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col5\" class=\"data row4 col5\" >96</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col6\" class=\"data row4 col6\" >104</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col7\" class=\"data row4 col7\" >107</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col8\" class=\"data row4 col8\" >22</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row4_col9\" class=\"data row4 col9\" >16</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7level0_row5\" class=\"row_heading level0 row5\" >dog</th>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col0\" class=\"data row5 col0\" >8</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col1\" class=\"data row5 col1\" >15</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col2\" class=\"data row5 col2\" >37</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col3\" class=\"data row5 col3\" >162</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col4\" class=\"data row5 col4\" >70</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col5\" class=\"data row5 col5\" >556</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col6\" class=\"data row5 col6\" >34</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col7\" class=\"data row5 col7\" >80</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col8\" class=\"data row5 col8\" >19</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row5_col9\" class=\"data row5 col9\" >19</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7level0_row6\" class=\"row_heading level0 row6\" >frog</th>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col0\" class=\"data row6 col0\" >3</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col1\" class=\"data row6 col1\" >29</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col2\" class=\"data row6 col2\" >38</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col3\" class=\"data row6 col3\" >143</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col4\" class=\"data row6 col4\" >149</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col5\" class=\"data row6 col5\" >44</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col6\" class=\"data row6 col6\" >539</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col7\" class=\"data row6 col7\" >18</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col8\" class=\"data row6 col8\" >7</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row6_col9\" class=\"data row6 col9\" >30</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7level0_row7\" class=\"row_heading level0 row7\" >horse</th>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col0\" class=\"data row7 col0\" >19</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col1\" class=\"data row7 col1\" >18</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col2\" class=\"data row7 col2\" >17</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col3\" class=\"data row7 col3\" >56</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col4\" class=\"data row7 col4\" >78</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col5\" class=\"data row7 col5\" >138</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col6\" class=\"data row7 col6\" >17</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col7\" class=\"data row7 col7\" >591</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col8\" class=\"data row7 col8\" >10</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row7_col9\" class=\"data row7 col9\" >56</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7level0_row8\" class=\"row_heading level0 row8\" >ship</th>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col0\" class=\"data row8 col0\" >94</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col1\" class=\"data row8 col1\" >116</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col2\" class=\"data row8 col2\" >8</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col3\" class=\"data row8 col3\" >17</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col4\" class=\"data row8 col4\" >11</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col5\" class=\"data row8 col5\" >21</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col6\" class=\"data row8 col6\" >4</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col7\" class=\"data row8 col7\" >14</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col8\" class=\"data row8 col8\" >657</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row8_col9\" class=\"data row8 col9\" >58</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7level0_row9\" class=\"row_heading level0 row9\" >truck</th>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col0\" class=\"data row9 col0\" >25</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col1\" class=\"data row9 col1\" >241</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col2\" class=\"data row9 col2\" >5</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col3\" class=\"data row9 col3\" >22</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col4\" class=\"data row9 col4\" >7</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col5\" class=\"data row9 col5\" >16</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col6\" class=\"data row9 col6\" >19</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col7\" class=\"data row9 col7\" >38</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col8\" class=\"data row9 col8\" >79</td>\n",
              "                        <td id=\"T_a8c976c2_39db_11ed_ae3f_3d10fb810eb7row9_col9\" class=\"data row9 col9\" >548</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f287d737518>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "cm = sns.light_palette(\"green\", as_cmap=True)\n",
        "df.style.background_gradient(cmap=cm).set_precision(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hktUgjMojF5O"
      },
      "source": [
        "**Ejercicio:** Analizar los resultados anteriores, ¿vale la pena hacer algunos cambios al modelo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5Mk56NcjF5O"
      },
      "source": [
        "## CNNs para Texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQMY_yMSjF5O"
      },
      "source": [
        "### Datos IMDB\n",
        "\n",
        "Similar al caso de CNN para imágenes, vamos a volver sobre el conjunto de datos que ya utilizamos anteriomente: el de reviews IMDB. Esta vez para compararlo contra el modelo de perceptrón multicapa utilizando la media de los embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXzTsuEtjF5O"
      },
      "outputs": [],
      "source": [
        "class IMDBReviewsDataset(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.dataset.shape[0]\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        if torch.is_tensor(item):\n",
        "            item = item.to_list()\n",
        "        \n",
        "        item = {\n",
        "            \"data\": self.dataset.loc[item, \"review\"],\n",
        "            \"target\": self.dataset.loc[item, \"sentiment\"]\n",
        "        }\n",
        "        \n",
        "        if self.transform:\n",
        "            item = self.transform(item)\n",
        "        \n",
        "        return item"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf6ZhstEjF5O"
      },
      "source": [
        "### Preprocesamiento\n",
        "\n",
        "Aplicamos el mismo tipo de preprocesamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8dwS_tZjF5P"
      },
      "source": [
        "**Algunas funciones auxiliares:**\n",
        "-  [`gensim.parsing.preprocessing.preprocess_string`](https://radimrehurek.com/gensim/parsing/preprocessing.html#:~:text=gensim.parsing.preprocessing.preprocess_string(s%2C%20filters%3D%5B%3Cfunction%20%3Clambda%3E%3E%2C%20%3Cfunction%20strip_tags%3E%2C%20%3Cfunction%20strip_punctuation%3E%2C%20%3Cfunction%20strip_multiple_whitespaces%3E%2C%20%3Cfunction%20strip_numeric%3E%2C%20%3Cfunction%20remove_stopwords%3E%2C%20%3Cfunction%20strip_short%3E%2C%20%3Cfunction%20stem_text%3E%5D)): Apply list of chosen filters to a string.\n",
        "\n",
        "- [`corpora.Dictionary`](https://radimrehurek.com/gensim/corpora/dictionary.html#:~:text=word%3C%2D%3Eid%20mappings-,corpora.dictionary%20%E2%80%93%20Construct%20word%3C%2D%3Eid%20mappings,of%20a%20Dictionary%20%E2%80%93%20a%20mapping%20between%20words%20and%20their%20integer%20ids.,-class): This module implements the concept of a Dictionary – a mapping between words and their integer ids.\n",
        "\n",
        "-  [`Dictionary.filter_extremes`](https://radimrehurek.com/gensim/corpora/dictionary.html?highlight=filter_extremes#gensim.corpora.dictionary.Dictionary.filter_extremes:~:text=filter_extremes(no_below%3D5%2C%20no_above%3D0.5%2C%20keep_n%3D100000%2C%20keep_tokens%3DNone))\n",
        "\n",
        "-  [`Dictionary.compactify`](https://radimrehurek.com/gensim/corpora/dictionary.html?highlight=compactify#gensim.corpora.dictionary.Dictionary.compactify:~:text=compactify(),shrinking%20any%20gaps.)\n",
        "\n",
        "- [`Dictionary.patch_with_special_tokens`](https://radimrehurek.com/gensim/corpora/dictionary.html?highlight=patch_with_special_tokens#gensim.corpora.dictionary.Dictionary.patch_with_special_tokens:~:text=patch_with_special_tokens(special_token_dict)): Patch token2id and id2token using a dictionary of special tokens.\n",
        "\n",
        "- [`Dictionary.doc2idx`](https://radimrehurek.com/gensim/corpora/dictionary.html#:~:text=doc2idx(document%2C%20unknown_word_index%3D%2D1)): Convert document (a list of words) into a list of indexes = list of token_id. Replace all unknown words i.e, words not in the dictionary with the index as set via unknown_word_index.\n",
        "\n",
        "- [`__call__`](https://www.geeksforgeeks.org/__call__-in-python/): Permite que las instancias de una clase se comporten como funciones y puedan ser llamadas como funciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXiuU6h7jF5P"
      },
      "outputs": [],
      "source": [
        "class RawDataProcessor:\n",
        "    def __init__(self, \n",
        "                 dataset, \n",
        "                 ignore_header=True, \n",
        "                 filters=None, \n",
        "                 vocab_size=50000):\n",
        "        if filters:\n",
        "            self.filters = filters\n",
        "        else:\n",
        "            self.filters = [ #We set some filters\n",
        "                lambda s: s.lower(),\n",
        "                preprocessing.strip_tags,\n",
        "                preprocessing.strip_punctuation,\n",
        "                preprocessing.strip_multiple_whitespaces,\n",
        "                preprocessing.strip_numeric,\n",
        "                preprocessing.remove_stopwords,\n",
        "                preprocessing.strip_short,\n",
        "            ]\n",
        "        # Create dictionary based on all the reviews (with corresponding preprocessing and filters)\n",
        "        # The dictionary has idx as a key and word as a value\n",
        "        # For example one element could be (0, 'accustomed') or (1, 'agenda')\n",
        "        self.dictionary = corpora.Dictionary(\n",
        "            dataset[\"review\"].map(self._preprocess_string).tolist()\n",
        "        )\n",
        "        \n",
        "        # Filter the dictionary and compactify it (make the indices continous)\n",
        "        self.dictionary.filter_extremes(no_below=2, no_above=1, keep_n=vocab_size)\n",
        "        self.dictionary.compactify()\n",
        "        # Add a couple of special tokens\n",
        "        self.dictionary.patch_with_special_tokens({\n",
        "            \"[PAD]\": 0, #The padding token\n",
        "            \"[UNK]\": 1  # The unknown token\n",
        "        })\n",
        "        \n",
        "        self.idx_to_target = sorted(dataset[\"sentiment\"].unique())\n",
        "        self.target_to_idx = {t: i for i, t in enumerate(self.idx_to_target)}\n",
        "        \n",
        "\n",
        "    def _preprocess_string(self, string):\n",
        "        return preprocessing.preprocess_string(string, filters=self.filters)\n",
        "\n",
        "    def _sentence_to_indices(self, sentence):\n",
        "        return self.dictionary.doc2idx(sentence, unknown_word_index=1)\n",
        "    \n",
        "    def encode_data(self, data):\n",
        "        return self._sentence_to_indices(self._preprocess_string(data))\n",
        "    \n",
        "    def encode_target(self, target):\n",
        "        return self.target_to_idx[target]\n",
        "    \n",
        "    def __call__(self, item):\n",
        "        #Encodeamos tanto los datos como los targets, diferenciandos los casos cuando son strings y cuando no\n",
        "        if isinstance(item[\"data\"], str): \n",
        "            data = self.encode_data(item[\"data\"])\n",
        "        else:\n",
        "            data = [self.encode_data(d) for d in item[\"data\"]]\n",
        "        \n",
        "        if isinstance(item[\"target\"], str):\n",
        "            target = self.encode_target(item[\"target\"])\n",
        "        else:\n",
        "            target = [self.encode_target(t) for t in item[\"target\"]]\n",
        "        \n",
        "        return {\n",
        "            \"data\": data,\n",
        "            \"target\": target\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYu-BdzqjF5P"
      },
      "source": [
        "### Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g__PSAcajF5Q",
        "outputId": "fe19b06e-f3f3-48fa-a8d7-e8446696d446"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16222</th>\n",
              "      <td>I would like if they brought back surface. I r...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25713</th>\n",
              "      <td>If you know anything about the Manhattan Proje...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36405</th>\n",
              "      <td>It says a lot about the United Kingdom when te...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14862</th>\n",
              "      <td>1st watched 5/17/2002 - 3 out of 10(Dir-Ewald ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29570</th>\n",
              "      <td>Although the production and Jerry Jameson's di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "16222  I would like if they brought back surface. I r...  positive\n",
              "25713  If you know anything about the Manhattan Proje...  positive\n",
              "36405  It says a lot about the United Kingdom when te...  negative\n",
              "14862  1st watched 5/17/2002 - 3 out of 10(Dir-Ewald ...  negative\n",
              "29570  Although the production and Jerry Jameson's di...  negative"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = pd.read_csv(\"./data/imdb_reviews.csv.gz\")\n",
        "dataset.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWn-ppyQjF5Q"
      },
      "outputs": [],
      "source": [
        "preprocess = RawDataProcessor(dataset)\n",
        "#Separamos los datos de entrenamiento y test e instanciamos ambos conjuntos\n",
        "train_indices, test_indices = train_test_split(dataset.index, test_size=0.2, random_state=42)\n",
        "train_dataset = IMDBReviewsDataset(dataset.loc[train_indices].reset_index(drop=True), \n",
        "                                   transform=preprocess)\n",
        "test_dataset = IMDBReviewsDataset(dataset.loc[test_indices].reset_index(drop=True), \n",
        "                                  transform=preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn4pzM6ZjF5Q",
        "outputId": "858bb51e-8031-4450-c1d0-f06ba5d24f90"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30720</th>\n",
              "      <td>After watching Awake,I led to a conclusion:dir...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1320</th>\n",
              "      <td>There was such a hype about a game show with B...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23829</th>\n",
              "      <td>Perhaps one of the best movies ever made. Orry...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37073</th>\n",
              "      <td>This movie is a nonsense/spoof comedy, in the ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14877</th>\n",
              "      <td>My family truly enjoyed this movie. As far as ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15973</th>\n",
              "      <td>For 50 years after world war 2 the United Stat...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35576</th>\n",
              "      <td>Although Super Mario 64 isn't like the rest of...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30685</th>\n",
              "      <td>This movie wasted 2 hours of my time and just ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16134</th>\n",
              "      <td>This installment of Masters of Horror was terr...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37322</th>\n",
              "      <td>This may not be one of the best movies ever ma...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "30720  After watching Awake,I led to a conclusion:dir...  negative\n",
              "1320   There was such a hype about a game show with B...  negative\n",
              "23829  Perhaps one of the best movies ever made. Orry...  positive\n",
              "37073  This movie is a nonsense/spoof comedy, in the ...  negative\n",
              "14877  My family truly enjoyed this movie. As far as ...  positive\n",
              "15973  For 50 years after world war 2 the United Stat...  negative\n",
              "35576  Although Super Mario 64 isn't like the rest of...  positive\n",
              "30685  This movie wasted 2 hours of my time and just ...  negative\n",
              "16134  This installment of Masters of Horror was terr...  negative\n",
              "37322  This may not be one of the best movies ever ma...  positive"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset.dataset.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v7d3l-ljF5R"
      },
      "source": [
        "### Padding de secuencias\n",
        "\n",
        "Dado que en este caso utilizaremos las secuencias completas sobre las que aplicaremos las convoluciones, necesitamos trabajar con dichas secuencias de manera que en un batch de datos tengan el tamaño correcto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZ3AS-g3jF5R"
      },
      "outputs": [],
      "source": [
        "class PadSequences:\n",
        "    def __init__(self, \n",
        "                 pad_value=0, \n",
        "                 max_length=None, \n",
        "                 min_length=1):\n",
        "        \n",
        "        assert max_length is None or min_length <= max_length #Sanity check\n",
        "        self.pad_value = pad_value\n",
        "        self.max_length = max_length\n",
        "        self.min_length = min_length\n",
        "\n",
        "    def __call__(self, items):\n",
        "        data, target = list(zip(*[(item[\"data\"], item[\"target\"]) for item in items]))\n",
        "        seq_lengths = [len(d) for d in data]\n",
        "\n",
        "        if self.max_length:\n",
        "            max_length = self.max_length\n",
        "            seq_lengths = [min(self.max_length, l) for l in seq_lengths]\n",
        "        else:\n",
        "            # Si no tenemos max_lenght definido, tomamos el mínimo entre min_lenght y\n",
        "            # la longitud de la máxima secuencia\n",
        "            max_length = max(self.min_length, max(seq_lengths))\n",
        "        \n",
        "        \n",
        "        # Para secuencias cuya longitud es menor que max_lenght rellenamos los valores\n",
        "        # faltantes con 0 (pad_value)\n",
        "        data = [d[:l] + [self.pad_value] * (max_length - l)\n",
        "                for d, l in zip(data, seq_lengths)]\n",
        "    \n",
        "        return {\n",
        "            \"data\": torch.LongTensor(data),\n",
        "            \"target\": torch.FloatTensor(target)\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHn8X70ZjF5R"
      },
      "source": [
        "### DataLoaders\n",
        "\n",
        "Una vez creada nuestra función para hacer padding de secuencia, definiremos los `DataLoader`s. Una cuestión importante, las redes convolucionales sobre text esperan que todas las secuencias sean al menos del tamaño de la convolución máxima (caso contrario ocurrirá un error por no poder realizar la convolución sobre un espacio más chico que el tamaño de la convolución). Es por eso que utilizamos el parámetro `min_length` esta vez."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siQCHjlxjF5R"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 2\n",
        "FILTERS_COUNT = 100\n",
        "FILTERS_LENGTH = [2, 3, 4]\n",
        "\n",
        "#Instanciamos las clases\n",
        "pad_sequences = PadSequences(min_length=max(FILTERS_LENGTH))\n",
        "train_loader = DataLoader(train_dataset, \n",
        "                          batch_size=128, \n",
        "                          shuffle=True,\n",
        "                          collate_fn=pad_sequences, #Aplicamos padding a las secuencias durante la creación del bath\n",
        "                          drop_last=False)\n",
        "test_loader = DataLoader(test_dataset, \n",
        "                         batch_size=128, \n",
        "                         shuffle=False,\n",
        "                         collate_fn=pad_sequences, #Aplicamos padding a las secuencias durante la creación del bath\n",
        "                         drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y1R6MLwjF5R"
      },
      "source": [
        "### Red convolucional sobre texto\n",
        "\n",
        "Por último, tenemos la red convolucional sobre texto. Si bien arranca muy similar al caso del clasificador del perceptrón multicapa, vemos que en este caso hacemos uso de [`torch.nn.Conv1d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html) dado que sólo nos desplazamos por una dimensión (i.e. la secuencia). En particular, como utilizamos *max pooling* global, no hacemos uso del módulo `torch.nn` para calcularlo, simplemente utilizamos el método `max()` del tensor.\n",
        "\n",
        "**Algunas funciones auxiliares:**\n",
        "- [`torch.nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html): A simple lookup table that stores embeddings of a fixed dictionary and size.This module is often used to store word embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings.\n",
        "\n",
        "- [`nn.Embedding.from_pretrained`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#:~:text=CLASSMETHOD%20from_pretrained(embeddings%2C%20freeze%3DTrue%2C%20padding_idx%3DNone%2C%20max_norm%3DNone%2C%20norm_type%3D2.0%2C%20scale_grad_by_freq%3DFalse%2C%20sparse%3DFalse)): Creates Embedding instance from given 2-dimensional FloatTensor.\n",
        "\n",
        "- [`torch.nn.ModuleList`](https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html?highlight=modulelist#torch.nn.ModuleList:~:text=torch.nn.ModuleList(modules%3DNone)): Holds submodules in a list.\n",
        "\n",
        "- [`torch.cat`](https://pytorch.org/docs/stable/generated/torch.cat.html?highlight=torch%20cat#torch.cat:~:text=torch.cat(tensors%2C%20dim%3D0%2C%20*%2C%20out%3DNone)%20%E2%86%92%20Tensor): Concatenates the given sequence of seq tensors in the given dimension. All tensors must either have the same shape (except in the concatenating dimension) or be empty.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSeA8sRsjF5S"
      },
      "outputs": [],
      "source": [
        "class IMDBReviewsClassifier(nn.Module):\n",
        "    def __init__(self, \n",
        "                 pretrained_embeddings_path, \n",
        "                 dictionary,\n",
        "                 vector_size,\n",
        "                 freeze_embedings):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Inicializamos la matriz de embeddings\n",
        "        embeddings_matrix = torch.randn(len(dictionary), vector_size)\n",
        "        embeddings_matrix[0] = torch.zeros(vector_size)\n",
        "        \n",
        "        #Trabajamos con los embeddings preentrenados\n",
        "        with gzip.open(pretrained_embeddings_path, \"rt\") as fh:\n",
        "            for line in fh:\n",
        "                word, vector = line.strip().split(None, 1)\n",
        "                if word in dictionary.token2id:\n",
        "                    embeddings_matrix[dictionary.token2id[word]] =\\\n",
        "                        torch.FloatTensor([float(n) for n in vector.split()])\n",
        "        \n",
        "        # Los guardamos en la variable embeddings\n",
        "        self.embeddings = nn.Embedding.from_pretrained(embeddings_matrix,\n",
        "                                                       freeze=freeze_embedings,\n",
        "                                                       padding_idx=0)\n",
        "        self.convs = []\n",
        "        for filter_lenght in FILTERS_LENGTH:\n",
        "            self.convs.append(\n",
        "                nn.Conv1d(vector_size, FILTERS_COUNT, filter_lenght) #(in_channels, out_channels, kernel_size)\n",
        "            )\n",
        "        self.convs = nn.ModuleList(self.convs)\n",
        "        self.fc = nn.Linear(FILTERS_COUNT * len(FILTERS_LENGTH), 128)\n",
        "        self.output = nn.Linear(128, 1)\n",
        "        self.vector_size = vector_size\n",
        "    \n",
        "    @staticmethod\n",
        "    def conv_global_max_pool(x, conv):\n",
        "        return F.relu(conv(x).transpose(1, 2).max(1)[0])\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x).transpose(1, 2)  \n",
        "        x = [self.conv_global_max_pool(x, conv) for conv in self.convs]\n",
        "        x = torch.cat(x, dim=1)\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = torch.sigmoid(self.output(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUKoGwKTjF5S"
      },
      "source": [
        "### Experimento\n",
        "\n",
        "El experimento de MLflow es prácticamente igual, salvo que cambiamos algunos de los parámetros a guardar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEypLUdojF5S"
      },
      "outputs": [],
      "source": [
        "mlflow.set_experiment(\"a_naive_experiment\")\n",
        "\n",
        "with mlflow.start_run():\n",
        "    mlflow.log_param(\"model_name\", \"cnn\")\n",
        "    mlflow.log_param(\"freeze_embedding\", True)\n",
        "    mlflow.log_params({\n",
        "        \"filters_count\": FILTERS_COUNT,\n",
        "        \"filters_length\": FILTERS_LENGTH,\n",
        "        \"fc_size\": 128\n",
        "    })\n",
        "    model = IMDBReviewsClassifier(\"./data/glove.6B.50d.txt.gz\", preprocess.dictionary, 50, True)\n",
        "    loss = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "    for epoch in trange(3):\n",
        "        model.train()\n",
        "        running_loss = []\n",
        "        for idx, batch in enumerate(tqdm(train_loader)):\n",
        "            optimizer.zero_grad()\n",
        "            output = model(batch[\"data\"])\n",
        "            loss_value = loss(output, batch[\"target\"].view(-1, 1))\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "            running_loss.append(loss_value.item())        \n",
        "        mlflow.log_metric(\"train_loss\", sum(running_loss) / len(running_loss), epoch)\n",
        "        \n",
        "        model.eval()\n",
        "        running_loss = []\n",
        "        targets = []\n",
        "        predictions = []\n",
        "        for batch in tqdm(test_loader):\n",
        "            output = model(batch[\"data\"])\n",
        "            running_loss.append(\n",
        "                loss(output, batch[\"target\"].view(-1, 1)).item()\n",
        "            )\n",
        "            targets.extend(batch[\"target\"].numpy())\n",
        "            predictions.extend(output.squeeze().detach().numpy())\n",
        "        mlflow.log_metric(\"test_loss\", sum(running_loss) / len(running_loss), epoch)\n",
        "        mlflow.log_metric(\"test_avp\", average_precision_score(targets, predictions), epoch)\n",
        "    \n",
        "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
        "        targets = []\n",
        "        predictions = []\n",
        "        for batch in tqdm(test_loader):\n",
        "            output = model(batch[\"data\"])\n",
        "            targets.extend(batch[\"target\"].numpy())\n",
        "            predictions.extend(output.squeeze().detach().numpy())\n",
        "        pd.DataFrame({\"prediction\": predictions, \"target\": targets}).to_csv(\n",
        "            f\"{tmpdirname}/predictions.csv.gz\", index=False\n",
        "        )\n",
        "        mlflow.log_artifact(f\"{tmpdirname}/predictions.csv.gz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTTKflqgjF5T",
        "outputId": "ccfa8e16-6419-497c-896f-128cbc05ac16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IMDBReviewsClassifier(\n",
            "  (embeddings): Embedding(50002, 50, padding_idx=0)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(50, 100, kernel_size=(2,), stride=(1,))\n",
            "    (1): Conv1d(50, 100, kernel_size=(3,), stride=(1,))\n",
            "    (2): Conv1d(50, 100, kernel_size=(4,), stride=(1,))\n",
            "  )\n",
            "  (fc): Linear(in_features=300, out_features=128, bias=True)\n",
            "  (output): Linear(in_features=128, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcMlwFf0jF5T"
      },
      "outputs": [],
      "source": [
        "mlflow.tracking.MlflowClient().list_experiments()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhisTKDRjF5T"
      },
      "outputs": [],
      "source": [
        "mlflow.search_runs().head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_oPdjsYjF5T"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "rise": {
      "scroll": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
