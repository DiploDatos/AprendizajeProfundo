{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Manejo de Datos en PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import functools\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "import tempfile\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.parsing import preprocessing\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## La clase Dataset\n",
    "\n",
    "La clase abstracta [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) es la clase base para construir un dataset de PyTorch. Cualquier dataset personalizado debe heredar de dicha clase e implementar los siguientes métodos:\n",
    "\n",
    "- `__len__`: Para que `len(dataset)` devuelva el tamaño del conjunto de datos.\n",
    "- `__getitem__`: Para soportar indexado de manera que `dataset[i]` devuelva el elemento `i`. Es común que en ciertos casos se utilice este método para levantar el dato real (e.g. una imagen) mientras que lo que se guarde en el dataset sea sólo una referencia a dicho dato (e.g. un path a la imagen). De esta manera se evita cargar muchas imágenes en memoria, haciendo que sea menos demandante a nivel RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class IMDBReviewsDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.dataset = pd.read_csv(path)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if torch.is_tensor(item):\n",
    "            item = item.tolist()  # Deal with list of items instead of tensor\n",
    "        \n",
    "        item = {\n",
    "            \"data\": self.dataset.iloc[item][\"review\"],\n",
    "            \"target\": self.dataset.iloc[item][\"sentiment\"]\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            item = self.transform(item)\n",
    "        \n",
    "        return item\n",
    "\n",
    "dataset = IMDBReviewsDataset(\"./data/imdb_reviews.csv.gz\")\n",
    "print(f\"Dataset loaded with {len(dataset)} elements\")\n",
    "print(f\"Sample element:\\n{dataset[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformaciones\n",
    "\n",
    "El ejemplo anterior nos muestra el uso básico, pero claramente no podemos pasarle eso a una red neuronal, no puede manejar texto. Es para eso que tenemos que hacer algún tipo de transformación sobre los atributos (en este caso el único atributo es el texto). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Normalización\n",
    "\n",
    "En particular, como vemos en el caso anterior, el texto no está normalizado, parte de las transformaciones pueden incluir realizar algún tipo de normalización. Para eso hagamos uso de [`gensim`](https://radimrehurek.com/gensim/index.html), en particular utilizaremos el módulo [`preprocessing`](https://radimrehurek.com/gensim/parsing/preprocessing.html#module-gensim.parsing.preprocessing) que se encargará de hacer varias normalizaciones por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class TextPreprocess:\n",
    "    def __init__(self, filters=None):\n",
    "        if filters:\n",
    "            self.filters = filters\n",
    "        else:\n",
    "            self.filters = [\n",
    "                lambda s: s.lower(),\n",
    "                preprocessing.strip_tags,\n",
    "                preprocessing.strip_punctuation,\n",
    "                preprocessing.strip_multiple_whitespaces,\n",
    "                preprocessing.strip_numeric,\n",
    "                preprocessing.remove_stopwords,\n",
    "                preprocessing.strip_short,\n",
    "            ]\n",
    "        \n",
    "    def _preprocess_string(self, string):\n",
    "        return preprocessing.preprocess_string(string, filters=self.filters)\n",
    "\n",
    "    def _encode_target(self, target):\n",
    "        return 1 if target == \"positive\" else 0\n",
    "\n",
    "    def __call__(self, item):\n",
    "        if isinstance(item[\"data\"], str):\n",
    "            data = self._preprocess_string(item[\"data\"])\n",
    "        else:\n",
    "            data = [self._preprocess_string(d) for d in item[\"data\"]]\n",
    "        \n",
    "        if isinstance(item[\"target\"], str):\n",
    "            target = self._encode_target(item[\"target\"])\n",
    "        else:\n",
    "            target = [self._encode_target(t) for t in item[\"target\"]]\n",
    "        \n",
    "        return {\n",
    "            \"data\": data,\n",
    "            \"target\": target\n",
    "        }\n",
    "\n",
    "preprocess = TextPreprocess()\n",
    "print(preprocess(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Conversión a vectores\n",
    "\n",
    "Podemos continuar convertiendo el texto en una representación por vectores. Si bien hay muchas posibilidades (siendo la bolsa de palabras una de las más utilizadas), en general para Deep Learning se prefieren representaciones utilizando vectores contínuos, obtenidos por algún método del estilo de Word2Vec, Glove o FastText. Para este caso utilizaremos las representaciones de Glove de dimensión 50 que se dejaron para descargar en el [notebook 0](./0_set_up.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class VectorizeText:\n",
    "    def __init__(self, glove_vectors_path):\n",
    "        self.glove_model = KeyedVectors.load_word2vec_format(glove_vectors_path,\n",
    "                                                             binary=False, no_header=True)\n",
    "        self.unkown_vector = np.random.randn(self.glove_model.vector_size)  # Random vector for unknown words\n",
    "    \n",
    "    def _get_vector(self, word):\n",
    "        if word in self.glove_model:\n",
    "            return self.glove_model[word]\n",
    "        else:\n",
    "            return self.unkown_vector\n",
    "    \n",
    "    def _get_vectors(self, sentence):\n",
    "        return np.vstack([self._get_vector(word) for word in sentence])\n",
    "    \n",
    "    def __call__(self, item):\n",
    "        review = []\n",
    "        if isinstance(item[\"data\"][0], str):\n",
    "            review = self._get_vectors(item[\"data\"])\n",
    "        else:\n",
    "            review = [self._get_vectors(d) for d in item[\"data\"]]\n",
    "\n",
    "        return {\n",
    "            \"data\": review,\n",
    "            \"target\": item[\"target\"]\n",
    "        }\n",
    "\n",
    "vectorizer = VectorizeText(\"./data/glove.6B.50d.txt.gz\")\n",
    "vectorizer(preprocess(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Combinación de vectores\n",
    "\n",
    "Si bien ahora estamos con una versión de los atributos que podría pasar por una red neuronal, hay un problema, las distintas reviews tienen largo distinto y como el algoritmo se entrena en lotes (*mini-batches*) estas requieren tener todas el mismo largo. Hay varias maneras de lidiar con esto, cada una con sus ventajas y desventajas. Dado que por ahora solo vimos perceptrón multicapa, que espera algo de tamaño fijo, una opción sencilla puede ser la de simplemente promediar los vectores de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class WordVectorsAverage:\n",
    "    def __call__(self, item):\n",
    "        if item[\"data\"][0].ndim == 2:\n",
    "            data = np.vstack([np.mean(d, axis=0) for d in item[\"data\"]])\n",
    "        else:\n",
    "            data = np.mean(item[\"data\"], axis=0)\n",
    "        \n",
    "        return {\n",
    "            \"data\": data,\n",
    "            \"target\": item[\"target\"]\n",
    "        }\n",
    "\n",
    "vector_average = WordVectorsAverage()\n",
    "vector_average(vectorizer(preprocess(dataset[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Conversión de vectores a tensores\n",
    "\n",
    "En el paso final, debemos convertir nuestros datos de arrays de `numpy` a tensores de PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    def __call__(self, item):\n",
    "        \"\"\"\n",
    "        This espects a single array.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"data\": torch.from_numpy(item[\"data\"]),\n",
    "            \"target\": torch.tensor(item[\"target\"])\n",
    "        }\n",
    "\n",
    "to_tensor = ToTensor()\n",
    "to_tensor(vector_average(vectorizer(preprocess(dataset[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Componiendo las transformaciones\n",
    "\n",
    "Para evitar tener que llamar a todas las funciones de transformación que querramos aplicar, para ello hacemos uso del parámetro `transform` que definimos en nuestro `Dataset` y un poco de ayuda de `functools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def compose(*functions):\n",
    "    return functools.reduce(lambda f, g: lambda x: g(f(x)), functions, lambda x: x)\n",
    "\n",
    "dataset = IMDBReviewsDataset(\"./data/imdb_reviews.csv.gz\",\n",
    "                             transform=compose(preprocess, vectorizer, vector_average, to_tensor))\n",
    "print(f\"Dataset loaded with {len(dataset)} elements\")\n",
    "print(f\"Sample element:\\n{dataset[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Iterando el dataset\n",
    "\n",
    "Ya tenemos nuestro conjunto de datos con sus respectivas transformaciones. ¿Para qué nos sirve esto? Una opción es simplemente iterar en el conjunto de datos de a un elemento. Esto es sencillo, simplemente se hace a través de un `for`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for idx, sample in enumerate(dataset):\n",
    "    print(sample[\"data\"])\n",
    "    print(sample[\"target\"])\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if idx == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## La clase Dataloader\n",
    "\n",
    "El problema con iterar de a un elemento es que estamos limitados al querer entrenar un modelo. Por empezar, los modelos de Deep Learning suelen ser más eficientes si se entrenan utilizando algún tipo de entrenamiento por *mini-batches*. Además, hay otras cosas como mezclar los elementos (*shuffling*) o cargar datos en paralelo vía distintos *multiprocess workers*. La clase [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) precisamente se encarga de hacer eso por nosotros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, \n",
    "          sample_batched['data'].size(),\n",
    "          sample_batched['target'].size())\n",
    "\n",
    "    if i_batch == 2:\n",
    "        print(sample_batched[\"data\"])\n",
    "        print(sample_batched[\"target\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## La clase IterableDataset\n",
    "\n",
    "El método preferido para trabajar con conjuntos de datos en PyTorch es `torch.utils.data.Dataset`. En general, hacer uso inteligente del método `__getitem__`, e.g. usándolo para cargar imágenes a medida que sean necesitadas y no al instanciar el dataset, es la mejor manera de trabajar con un conjunto de datos. En particular, de esta forma es mucho más fácil hacer *shuffling* de los datos y demás. No obstante, no siempre esto es posible, muchas veces el conjunto de datos es demasiado grande para levantarlo en memoria (aunque sólo levantemos referencias). Para esos casos, PyTorch ofrece la clase [`torch.utils.data.IterableDataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset), en este caso el único método que es requerido implementar es `__iter__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class MeLiChallengeDataset(IterableDataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.dataset_path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __iter__(self):\n",
    "        with gzip.open(self.dataset_path, \"rt\") as fh:\n",
    "            for l in fh:\n",
    "                data = json.loads(l)\n",
    "                item = {\n",
    "                    \"data\": data['title'],\n",
    "                    \"target\": data['category']\n",
    "                }\n",
    "                \n",
    "                if self.transform:\n",
    "                    yield self.transform(item)\n",
    "                else:\n",
    "                    yield item\n",
    "\n",
    "dataset = MeLiChallengeDataset(\"./data/meli-challenge-2019/spanish.train.jsonl.gz\")\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "dataiter = iter(dataloader)\n",
    "print(f\"Sample batch:\\n{dataiter.next()}\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
