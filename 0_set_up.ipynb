{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje Profundo - Parte 0\n",
    "\n",
    "Este notebook explica cómo instalar todos los prerequisitos y librería que van a necesitar para correr los tutoriales. Si pueden ejecutar las siguientes celdas, estás listo.\n",
    "\n",
    "## Configuración del Entorno\n",
    "\n",
    "\n",
    "### Instalar conda\n",
    "\n",
    "Lo primero que necesitamos es instalar conda y crear un entorno para ejecutar el código. Hay dos formas de instalar conda: *Anaconda* y *Miniconda*. Cualquiera es útil para este curso. Simplemente seguí las instrucciones de acuerdo a tu sistema operativo.\n",
    "\n",
    "https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html#regular-installation\n",
    "\n",
    "### Crear un entorno con todas las librerías de Anaconda\n",
    "\n",
    "    $ conda create --name deeplearning python=3.9.5 anaconda\n",
    "\n",
    "No te olvides de activar el entorno\n",
    "\n",
    "    $ conda activate deeplearning    \n",
    "\n",
    "### Instalar PyTorch\n",
    "\n",
    "Vamos a estar trabajando con [PyTorch](https://pytorch.org/) para armar y entrenar modelos de aprendizaje profundo. La librería es menos abstracta que otras posibilidades como [Keras](https://www.tensorflow.org/guide/keras) pero da más control al usuario y permite crear soluciones más flexibles.\n",
    "\n",
    "Para instalar PyTorch recomendamos seguir la [documentación oficial](https://pytorch.org/get-started/locally/). En sus máquinas es mejor que instalen la versión con solo soporte para CPU (sin CUDA), pero en Nabucodonosor van a requerir una versión con soporte para GPU.\n",
    "\n",
    "#### CPU\n",
    "\n",
    "Instalar PyTorch para CPU:\n",
    "\n",
    "    (deeplearning) $ conda install pytorch torchvision cpuonly -c pytorch\n",
    "    \n",
    "Luego solo resta chequear que la versión instalada sea  >= 1.10. Para ejecutar las siguientes líneas de código abrir python dentro del entorno (es suficiente con escribir <code>python</code> en la consola que estén usando)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU\n",
    "\n",
    "La versión de GPU de PyTorch depende de la versión de CUDA instalada. Nabucodonosor tiene muchas instalaciones de CUDA en `/opt/cuda`. Tienen que agregar `nvcc` ([nvidia cuda compiler](https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html)) al `$PATH`. Por ejemplo, para CUDA 11.1, deben hacer lo siguiente:\n",
    "\n",
    "    (deeplearning) $ export PATH=/opt/cuda/11.1/bin:$PATH\n",
    "\n",
    "Eso se tiene que hacer cada vez que entren a nabucodonosor. Para evitar eso, pueden agregarlo a su `.bashrc`:\n",
    "\n",
    "    (deeplearning) $ echo \"export PATH=/opt/cuda/11.1/bin:$PATH\" >> $HOME/.bashrc\n",
    "\n",
    "Luego instalen la versión de PyTorch compatible con CUDA 11.1:\n",
    "\n",
    "    (deeplearning) $ pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "Pueden controlar que la instalación funcione corriendo lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si `torch.cuda.is_available()==True`, PyTorch puede usar las GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Colab\n",
    "\n",
    "En caso de que quieran usar PyTorch en Google Colab, es posible, pero primero deben controlar qué versión de `nvcc` está corriendo. Para eso corran el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo a lo que diga el comando anterior, tendrán que instalar los drivers apropiados con `pip`. Para más informacion vean la [documentación](https://pytorch.org/get-started/locally/) de cómo hacer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar otras librerías\n",
    "\n",
    "Necesitamos `gensim` para poder usar *word embeddings*, asi que necesitamos instalarlo. También necesitamos `mlflow` para hacer un seguimiento de los experimentos. Finalmente, `tqdm` es util para hacer barras de progreso para hacer un seguimiento del progreso.\n",
    "\n",
    "    (deeplearning) $ conda install gensim mlflow tqdm -c conda-forge\n",
    "\n",
    "Si tienen problemas importando `gensim` y tienen este error:\n",
    "\n",
    "    ImportError: cannot import name 'open' from 'smart_open' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\__init__.py)\n",
    "\n",
    "Intenten actualizando `smart_open`\n",
    "\n",
    "    (deeplearning) $ conda update smart_open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descargar embeddings y datasets\n",
    "\n",
    "### CIFAR10\n",
    "\n",
    "El dataset que usaremos (CIFAR10) es parte del paquete de `torchvision`, el cual lo hace muy simple de descargar. Pueden leer los detalles [aquí](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#loading-and-normalizing-cifar10):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "torchvision.datasets.CIFAR10(root='./data', download=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Embeddings y IMDB reviews Dataset\n",
    "\n",
    "Algunos ejemplos que vamos a correr para clasificación de texto usan Redes Neuronales Convolucionales y requieren los embeddings de Glove junto al dataset de IMDB reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "curl -L https://cs.famaf.unc.edu.ar/\\~ccardellino/resources/diplodatos/glove.6B.50d.txt.gz -o ./data/glove.6B.50d.txt.gz\n",
    "curl -L https://cs.famaf.unc.edu.ar/\\~ccardellino/resources/diplodatos/imdb_reviews.csv.gz -o ./data/imdb_reviews.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MeLi Challenge 2019 Dataset\n",
    "\n",
    "Para el proyecto del curso vamos a usar el dataset del MeLi Challenge 2019, para clasificación automática de categorías de productos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "curl -L https://cs.famaf.unc.edu.ar/\\~ccardellino/resources/diplodatos/meli-challenge-2019.tar.bz2 -o ./data/meli-challenge-2019.tar.bz2\n",
    "tar jxvf ./data/meli-challenge-2019.tar.bz2 -C ./data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Nabucodonosor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunneling y ssh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cómo correr un notebook en una máquina remota?** Usás una conección ssh con forwarding de puertos. De esta forma todo lo que va al puerto indicado en la máquina también va al localhost.\n",
    "\n",
    "Es posible que muchos quieran usar el mismo puerto, asi que recomendamos que elijan un numero al azar antes de conectarse (menos el 16006). El puerto en el ssh debe ser el mismo en el que inicial el notebook.\n",
    "\n",
    "```\n",
    "$ ssh -L PORT:localhost:PORT USER@nabucodonosor.ccad.unc.edu.ar\n",
    "$ conda activate deeplearning\n",
    "(deeplearning) $ jupyter notebook --port PORT --no-browser\n",
    "```\n",
    "\n",
    "Ahora pueden usar el notebook como si estuvieran corriendo en su computadora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evitar usar GPUs\n",
    "\n",
    "Si todas las GPUs están siendo usadas, se puede forzar a PyTorch a usar la CPU. Para modelos simples esta es una muy buena opción.\n",
    "\n",
    "La forma más facil es settear la variable de entorno `CUDA_VISIBLE_DEVICES=\"\"` cuando corren sus comandos. Por ejemplo:\n",
    "\n",
    "```\n",
    "(deeplearning) $ CUDA_VISIBLE_DEVICES=\"\" jupyter notebook --no-browser\n",
    "(deeplearning) $ CUDA_VISIBLE_DEVICES=\"\" exercise_1.py --experiment_name mlp_200\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
